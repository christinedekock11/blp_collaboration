{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "HOME = '/srv/home/christinedk/wp_internship/'\n",
    "DATA_DIR = HOME + 'data/'\n",
    "sys.path.append(HOME + 'collaboration/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from math import log2\n",
    "from utils import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "template='autobiography'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(HOME+'features/activity_{}.json'.format(template),'rb') as f:\n",
    "    features_pos = json.load(f)\n",
    "with open(HOME+'negative_features/activity_{}.json'.format(template),'rb') as f:\n",
    "    features_neg = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4224"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3376"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_features_neg = pd.DataFrame([d['article'] for d in features_neg])\n",
    "article_features_neg['label'] = 0\n",
    "article_features_pos = pd.DataFrame([d['article'] for d in features_pos])\n",
    "article_features_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data = pd.concat([article_features_neg, article_features_pos])\n",
    "labels = article_data['label']\n",
    "feat = article_data.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7600"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>frac_recent_revisions</td>\n",
       "      <td>0.482690</td>\n",
       "      <td>0.482690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>concentration_ratio</td>\n",
       "      <td>0.172245</td>\n",
       "      <td>0.172245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>contribution_frac_entropy</td>\n",
       "      <td>-0.165734</td>\n",
       "      <td>0.165734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>recent_edit_size</td>\n",
       "      <td>0.144688</td>\n",
       "      <td>0.144688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>top_contributor_frac</td>\n",
       "      <td>0.143939</td>\n",
       "      <td>0.143939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>edit_size</td>\n",
       "      <td>0.129611</td>\n",
       "      <td>0.129611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>frac_anon_revisions</td>\n",
       "      <td>-0.077423</td>\n",
       "      <td>0.077423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>time_to_respond</td>\n",
       "      <td>0.069562</td>\n",
       "      <td>0.069562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_revisions</td>\n",
       "      <td>-0.065043</td>\n",
       "      <td>0.065043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>frac_minor_edits</td>\n",
       "      <td>-0.061321</td>\n",
       "      <td>0.061321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature     score       abs\n",
       "8       frac_recent_revisions  0.482690  0.482690\n",
       "11        concentration_ratio  0.172245  0.172245\n",
       "12  contribution_frac_entropy -0.165734  0.165734\n",
       "13           recent_edit_size  0.144688  0.144688\n",
       "9        top_contributor_frac  0.143939  0.143939\n",
       "0                   edit_size  0.129611  0.129611\n",
       "10        frac_anon_revisions -0.077423  0.077423\n",
       "1             time_to_respond  0.069562  0.069562\n",
       "6               num_revisions -0.065043  0.065043\n",
       "4            frac_minor_edits -0.061321  0.061321"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = {'solver':'lbfgs','max_iter':10000,'C':10000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/lib/python3/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/christinedk/venv/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8418778077268644"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[665, 175],\n",
       "       [300, 760]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619047619047619"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_features(article_users):\n",
    "    if len(article_users) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        article_users = pd.DataFrame(article_users).drop('event_user_id',axis=1)\n",
    "        means = {'mean_'+key:val for key, val in article_users.mean().items()}\n",
    "        std = {'std_'+key:val for key, val in article_users.std().items()}\n",
    "        max_ = {'max_'+key:val for key, val in article_users.max().items()}\n",
    "        ent = {'frac_page_edits_ent': entropy(article_users.frac_page_edits)}\n",
    "        features = {**means, **std, **max_, **ent}\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_article_features_pos = pd.DataFrame([aggregate_features(d['user_article']) \n",
    "                                          for d in features_pos])\n",
    "user_article_features_neg = pd.DataFrame([aggregate_features(d['user_article']) \n",
    "                                          for d in features_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_article_features_pos['label'] = 1\n",
    "user_article_features_neg['label'] = 0\n",
    "\n",
    "user_article_data = pd.concat([user_article_features_neg,user_article_features_pos])\n",
    "labels = user_article_data['label']\n",
    "feat = user_article_data.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean_frac_page_edits</td>\n",
       "      <td>0.320860</td>\n",
       "      <td>0.320860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>frac_page_edits_ent</td>\n",
       "      <td>-0.195256</td>\n",
       "      <td>0.195256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>max_frac_page_edits</td>\n",
       "      <td>0.160401</td>\n",
       "      <td>0.160401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean_edit_size</td>\n",
       "      <td>0.127470</td>\n",
       "      <td>0.127470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>std_frac_page_edits</td>\n",
       "      <td>0.123100</td>\n",
       "      <td>0.123100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>std_edit_size</td>\n",
       "      <td>0.081161</td>\n",
       "      <td>0.081161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>std_revision_is_identity_revert</td>\n",
       "      <td>-0.064561</td>\n",
       "      <td>0.064561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean_time_to_respond</td>\n",
       "      <td>0.062493</td>\n",
       "      <td>0.062493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mean_time_responded_to</td>\n",
       "      <td>0.062403</td>\n",
       "      <td>0.062403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>max_num_edits</td>\n",
       "      <td>-0.053866</td>\n",
       "      <td>0.053866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            feature     score       abs\n",
       "5              mean_frac_page_edits  0.320860  0.320860\n",
       "24              frac_page_edits_ent -0.195256  0.195256\n",
       "21              max_frac_page_edits  0.160401  0.160401\n",
       "0                    mean_edit_size  0.127470  0.127470\n",
       "13              std_frac_page_edits  0.123100  0.123100\n",
       "8                     std_edit_size  0.081161  0.081161\n",
       "15  std_revision_is_identity_revert -0.064561  0.064561\n",
       "2              mean_time_to_respond  0.062493  0.062493\n",
       "3            mean_time_responded_to  0.062403  0.062403\n",
       "20                    max_num_edits -0.053866  0.053866"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7240801569877362"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[571, 278],\n",
       "       [364, 687]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.681547619047619"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# talk vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(HOME+'features/talk_{}.json'.format(template),'rb') as f:\n",
    "    talk_pos = json.load(f)\n",
    "with open(HOME+'negative_features/talk_{}.json'.format(template),'rb') as f:\n",
    "    talk_neg = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_vol_neg = pd.DataFrame([d['talk_volume'] for d in talk_neg])\n",
    "talk_vol_neg['label'] = 0\n",
    "talk_vol_pos = pd.DataFrame([d['talk_volume'] for d in talk_pos])\n",
    "talk_vol_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_vol = pd.concat([talk_vol_neg,talk_vol_pos])\n",
    "labels = talk_vol['label']\n",
    "feat = talk_vol.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean_response_time</td>\n",
       "      <td>0.081944</td>\n",
       "      <td>0.081944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frac_recent_revisions</td>\n",
       "      <td>0.039484</td>\n",
       "      <td>0.039484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>page_talk_ratio</td>\n",
       "      <td>-0.028584</td>\n",
       "      <td>0.028584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_revisions</td>\n",
       "      <td>-0.025806</td>\n",
       "      <td>0.025806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num_editors</td>\n",
       "      <td>-0.014642</td>\n",
       "      <td>0.014642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mean_edit_size</td>\n",
       "      <td>-0.003368</td>\n",
       "      <td>0.003368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>top_contributor_frac</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>0.003081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature     score       abs\n",
       "5     mean_response_time  0.081944  0.081944\n",
       "1  frac_recent_revisions  0.039484  0.039484\n",
       "6        page_talk_ratio -0.028584  0.028584\n",
       "0          num_revisions -0.025806  0.025806\n",
       "2            num_editors -0.014642  0.014642\n",
       "4         mean_edit_size -0.003368  0.003368\n",
       "3   top_contributor_frac  0.003081  0.003081"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/lib/python3/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/christinedk/venv/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5950850403975404"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[215, 649],\n",
       "       [150, 886]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6892259821081291"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# talk lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(HOME+'features/talk_{}.json'.format(template),'rb') as f:\n",
    "    talk_pos = json.load(f)\n",
    "with open(HOME+'negative_features/talk_{}.json'.format(template),'rb') as f:\n",
    "    talk_neg = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_language(talk_feat):\n",
    "    if len(talk_feat) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        all_utts = pd.DataFrame(list(np.concatenate(list(talk_feat.values()))))\n",
    "        means = {'mean_'+key:val for key, val in all_utts.mean().items()}\n",
    "        std = {'std_'+key:val for key, val in all_utts.std().items()}\n",
    "        max_ = {'max_'+key:val for key, val in all_utts.max().items()}\n",
    "        features = {**means, **std, **max_}\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_lang_neg = pd.DataFrame([aggregate_language(d['talk_language']) for d in talk_neg])\n",
    "talk_lang_neg['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3376"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(talk_lang_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_lang_pos = pd.DataFrame([aggregate_language(d['talk_language']) for d in talk_pos])\n",
    "talk_lang_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4224"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(talk_lang_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_lang = pd.concat([talk_lang_neg,talk_lang_pos])\n",
    "labels = talk_lang['label']\n",
    "feat = talk_lang.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>std_politeness_markers_==Gratitude==</td>\n",
       "      <td>-0.031645</td>\n",
       "      <td>0.031645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>max_politeness_markers_==Please_start==</td>\n",
       "      <td>-0.031310</td>\n",
       "      <td>0.031310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mean_politeness_markers_==Indirect_(greeting)==</td>\n",
       "      <td>-0.028187</td>\n",
       "      <td>0.028187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>max_politeness_markers_==Gratitude==</td>\n",
       "      <td>-0.028184</td>\n",
       "      <td>0.028184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>max_politeness_markers_==Please==</td>\n",
       "      <td>-0.027673</td>\n",
       "      <td>0.027673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mean_politeness_markers_==2nd_person==</td>\n",
       "      <td>-0.027588</td>\n",
       "      <td>0.027588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>max_politeness_markers_==Indirect_(greeting)==</td>\n",
       "      <td>-0.026661</td>\n",
       "      <td>0.026661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean_politeness_markers_==Please_start==</td>\n",
       "      <td>-0.026454</td>\n",
       "      <td>0.026454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>std_politeness_markers_==Please_start==</td>\n",
       "      <td>-0.025945</td>\n",
       "      <td>0.025945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>max_politeness_markers_==1st_person_start==</td>\n",
       "      <td>-0.025695</td>\n",
       "      <td>0.025695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            feature     score       abs\n",
       "29             std_politeness_markers_==Gratitude== -0.031645  0.031645\n",
       "45          max_politeness_markers_==Please_start== -0.031310  0.031310\n",
       "14  mean_politeness_markers_==Indirect_(greeting)== -0.028187  0.028187\n",
       "51             max_politeness_markers_==Gratitude== -0.028184  0.028184\n",
       "44                max_politeness_markers_==Please== -0.027673  0.027673\n",
       "12           mean_politeness_markers_==2nd_person== -0.027588  0.027588\n",
       "58   max_politeness_markers_==Indirect_(greeting)== -0.026661  0.026661\n",
       "1          mean_politeness_markers_==Please_start== -0.026454  0.026454\n",
       "23          std_politeness_markers_==Please_start== -0.025945  0.025945\n",
       "55      max_politeness_markers_==1st_person_start== -0.025695  0.025695"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4714312745604876"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 61, 768],\n",
       "       [ 94, 977]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6938920454545454"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# editors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def aggregate_editor(editor_feat):\n",
    "    if len(editor_feat) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        all_utts = pd.DataFrame(editor_feat).drop('event_user_id',axis=1)\n",
    "        means = {'mean_'+key:val for key, val in all_utts.mean().items()}\n",
    "        std = {'std_'+key:val for key, val in all_utts.std().items()}\n",
    "        max_ = {'max_'+key:val for key, val in all_utts.max().items()}\n",
    "        features = {**means, **std, **max_}\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(HOME+'features/editors{}_v2.json'.format(template),'rb') as f:\n",
    "    editors_pos = json.load(f)\n",
    "    \n",
    "with open(HOME+'negative_features/editors{}_v2.json'.format(template),'rb') as f:\n",
    "    editors_neg = json.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "editor_neg = pd.DataFrame([aggregate_editor(d['editor']) for d in editors_neg])\n",
    "editor_neg['label'] = 0\n",
    "editor_pos = pd.DataFrame([aggregate_editor(d['editor']) for d in editors_pos])\n",
    "editor_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "len(editor_neg)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "len(editor_pos)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "editor_data = pd.concat([editor_neg,editor_pos])\n",
    "labels = editor_data['label']\n",
    "feat = editor_data.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# editor-editor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def aggregate(df):\n",
    "    means = {'mean_'+key:val for key, val in df.mean().items()}\n",
    "    std = {'std_'+key:val for key, val in df.std().items()}\n",
    "    max_ = {'max_'+key:val for key, val in df.max().items()}\n",
    "    features = {**means, **std, **max_}\n",
    "    return features\n",
    "\n",
    "def aggregate_collab(editor_feat):\n",
    "    if len(editor_feat['undirected']) == 0:\n",
    "        features = {}\n",
    "        \n",
    "    else:\n",
    "        directed = pd.DataFrame(editor_feat['directed']).drop(['event_user_id','event_user_id_r'],axis=1)\n",
    "        undirected = pd.DataFrame(editor_feat['undirected']).drop('pair',axis=1)\n",
    "\n",
    "        dir_features = aggregate(directed)\n",
    "        undir_features = aggregate(undirected)\n",
    "\n",
    "        features = {**dir_features,**undir_features}\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "collab_neg = pd.DataFrame([aggregate_collab(d['collaboration']) for d in editors_neg])\n",
    "collab_neg['label'] = 0\n",
    "collab_pos = pd.DataFrame([aggregate_collab(d['collaboration']) for d in editors_pos])\n",
    "collab_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "collab_data = pd.concat([editor_neg,editor_pos])\n",
    "labels = collab_data['label']\n",
    "feat = collab_data.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = article_data['label']\n",
    "\n",
    "feat = pd.concat([ds.reset_index(drop=True).drop('label',axis=1) \n",
    "                  for ds in [article_data,talk_vol,talk_lang,user_article_data]],axis=1) #editor_data,collab_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7600"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>frac_recent_revisions</td>\n",
       "      <td>0.096268</td>\n",
       "      <td>0.096268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>article_age_years</td>\n",
       "      <td>0.082205</td>\n",
       "      <td>0.082205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>time_to_respond</td>\n",
       "      <td>0.076882</td>\n",
       "      <td>0.076882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>mean_time_to_respond</td>\n",
       "      <td>0.072649</td>\n",
       "      <td>0.072649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>mean_time_responded_to</td>\n",
       "      <td>0.066997</td>\n",
       "      <td>0.066997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mean_response_time</td>\n",
       "      <td>0.062515</td>\n",
       "      <td>0.062515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>num_editors</td>\n",
       "      <td>0.058598</td>\n",
       "      <td>0.058598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>max_time_to_respond</td>\n",
       "      <td>0.058216</td>\n",
       "      <td>0.058216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>top_contributor_frac</td>\n",
       "      <td>-0.056674</td>\n",
       "      <td>0.056674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>std_time_to_respond</td>\n",
       "      <td>0.056469</td>\n",
       "      <td>0.056469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature     score       abs\n",
       "8     frac_recent_revisions  0.096268  0.096268\n",
       "2         article_age_years  0.082205  0.082205\n",
       "1           time_to_respond  0.076882  0.076882\n",
       "90     mean_time_to_respond  0.072649  0.072649\n",
       "91   mean_time_responded_to  0.066997  0.066997\n",
       "20       mean_response_time  0.062515  0.062515\n",
       "17              num_editors  0.058598  0.058598\n",
       "106     max_time_to_respond  0.058216  0.058216\n",
       "18     top_contributor_frac -0.056674  0.056674\n",
       "98      std_time_to_respond  0.056469  0.056469"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/lib/python3/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/christinedk/venv/lib/python3.7/site-packages/ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)#,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8198512969588552"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[672, 188],\n",
       "       [330, 710]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7327141382868938"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thoughts:\n",
    "\n",
    "# article:\n",
    "# comparing to same pages means some features are less relevant; eg. num_editors, mean edit_size, top_contributor_frac, etc\n",
    "# recency features should be more important \n",
    "#     - calculate all features for recent revisions only as well?\n",
    "\n",
    "\n",
    "# user-article\n",
    "# empty for some negatives? sample page': 189559,'date': '2003-02-28 16:09:01'\n",
    "# revert features are incorrect, need to re-export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
