{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "HOME = '/srv/home/christinedk/wp_internship/'\n",
    "DATA_DIR = HOME + 'data/'\n",
    "sys.path.append(HOME + 'collaboration/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/least_angle.py:1097: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/least_angle.py:1344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/least_angle.py:1480: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/randomized_l1.py:320: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/randomized_l1.py:580: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=None,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from math import log2\n",
    "from utils import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "template='peacock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(HOME+'features/activity_{}.json'.format(template),'rb') as f:\n",
    "    features_pos = json.load(f)\n",
    "with open(HOME+'negative_features/activity_{}.json'.format(template),'rb') as f:\n",
    "    features_neg = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5174"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4282"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_features_neg = pd.DataFrame([d['article'] for d in features_neg])\n",
    "article_features_neg['label'] = 0\n",
    "article_features_pos = pd.DataFrame([d['article'] for d in features_pos])\n",
    "article_features_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data = pd.concat([article_features_neg, article_features_pos])\n",
    "labels = article_data['label']\n",
    "feat = article_data.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9456"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>frac_recent_revisions</td>\n",
       "      <td>0.346634</td>\n",
       "      <td>0.346634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>concentration_ratio</td>\n",
       "      <td>0.152984</td>\n",
       "      <td>0.152984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>recent_edit_size</td>\n",
       "      <td>0.116431</td>\n",
       "      <td>0.116431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>edit_size</td>\n",
       "      <td>0.108846</td>\n",
       "      <td>0.108846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>recent_response_time</td>\n",
       "      <td>0.103073</td>\n",
       "      <td>0.103073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>contribution_frac_entropy</td>\n",
       "      <td>-0.100749</td>\n",
       "      <td>0.100749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>top_contributor_frac</td>\n",
       "      <td>0.079093</td>\n",
       "      <td>0.079093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>time_to_respond</td>\n",
       "      <td>0.078141</td>\n",
       "      <td>0.078141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>frac_anon_revisions</td>\n",
       "      <td>-0.056411</td>\n",
       "      <td>0.056411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_revisions</td>\n",
       "      <td>-0.052714</td>\n",
       "      <td>0.052714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature     score       abs\n",
       "8       frac_recent_revisions  0.346634  0.346634\n",
       "11        concentration_ratio  0.152984  0.152984\n",
       "13           recent_edit_size  0.116431  0.116431\n",
       "0                   edit_size  0.108846  0.108846\n",
       "14       recent_response_time  0.103073  0.103073\n",
       "12  contribution_frac_entropy -0.100749  0.100749\n",
       "9        top_contributor_frac  0.079093  0.079093\n",
       "1             time_to_respond  0.078141  0.078141\n",
       "10        frac_anon_revisions -0.056411  0.056411\n",
       "6               num_revisions -0.052714  0.052714"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = {'solver':'lbfgs','max_iter':10000,'C':10000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/lib/python3/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/christinedk/venv/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7366428996228132"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[781, 272],\n",
       "       [525, 786]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6635711270578303"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_features(article_users):\n",
    "    if len(article_users) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        article_users = pd.DataFrame(article_users).drop('event_user_id',axis=1)\n",
    "        means = {'mean_'+key:val for key, val in article_users.mean().items()}\n",
    "        std = {'std_'+key:val for key, val in article_users.std().items()}\n",
    "        max_ = {'max_'+key:val for key, val in article_users.max().items()}\n",
    "        ent = {'frac_page_edits_ent': entropy(article_users.frac_page_edits)}\n",
    "        features = {**means, **std, **max_, **ent}\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_article_features_pos = pd.DataFrame([aggregate_features(d['user_article']) \n",
    "                                          for d in features_pos])\n",
    "user_article_features_neg = pd.DataFrame([aggregate_features(d['user_article']) \n",
    "                                          for d in features_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_article_features_pos['label'] = 1\n",
    "user_article_features_neg['label'] = 0\n",
    "\n",
    "user_article_data = pd.concat([user_article_features_neg,user_article_features_pos])\n",
    "labels = user_article_data['label']\n",
    "feat = user_article_data.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean_frac_page_edits</td>\n",
       "      <td>0.233273</td>\n",
       "      <td>0.233273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>frac_page_edits_ent</td>\n",
       "      <td>-0.120467</td>\n",
       "      <td>0.120467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean_edit_size</td>\n",
       "      <td>0.096732</td>\n",
       "      <td>0.096732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>max_frac_page_edits</td>\n",
       "      <td>0.090276</td>\n",
       "      <td>0.090276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>std_frac_page_edits</td>\n",
       "      <td>0.082525</td>\n",
       "      <td>0.082525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean_time_to_respond</td>\n",
       "      <td>0.074941</td>\n",
       "      <td>0.074941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mean_time_responded_to</td>\n",
       "      <td>0.069068</td>\n",
       "      <td>0.069068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>max_num_edits</td>\n",
       "      <td>-0.058767</td>\n",
       "      <td>0.058767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>std_num_edits</td>\n",
       "      <td>-0.058611</td>\n",
       "      <td>0.058611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>std_time_to_respond</td>\n",
       "      <td>0.052783</td>\n",
       "      <td>0.052783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature     score       abs\n",
       "5     mean_frac_page_edits  0.233273  0.233273\n",
       "24     frac_page_edits_ent -0.120467  0.120467\n",
       "0           mean_edit_size  0.096732  0.096732\n",
       "21     max_frac_page_edits  0.090276  0.090276\n",
       "13     std_frac_page_edits  0.082525  0.082525\n",
       "2     mean_time_to_respond  0.074941  0.074941\n",
       "3   mean_time_responded_to  0.069068  0.069068\n",
       "20           max_num_edits -0.058767  0.058767\n",
       "12           std_num_edits -0.058611  0.058611\n",
       "10     std_time_to_respond  0.052783  0.052783"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6557479861910241"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[638, 462],\n",
       "       [499, 765]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6142111601766359"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# talk vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(HOME+'features/talk_{}.json'.format(template),'rb') as f:\n",
    "    talk_pos = json.load(f)\n",
    "with open(HOME+'negative_features/talk_{}.json'.format(template),'rb') as f:\n",
    "    talk_neg = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_vol_neg = pd.DataFrame([d['talk_volume'] for d in talk_neg])\n",
    "talk_vol_neg['label'] = 0\n",
    "talk_vol_pos = pd.DataFrame([d['talk_volume'] for d in talk_pos])\n",
    "talk_vol_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_vol = pd.concat([talk_vol_neg,talk_vol_pos])\n",
    "labels = talk_vol['label']\n",
    "feat = talk_vol.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean_response_time</td>\n",
       "      <td>0.062737</td>\n",
       "      <td>0.062737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>page_talk_ratio</td>\n",
       "      <td>-0.033946</td>\n",
       "      <td>0.033946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frac_recent_revisions</td>\n",
       "      <td>0.030090</td>\n",
       "      <td>0.030090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num_editors</td>\n",
       "      <td>-0.027779</td>\n",
       "      <td>0.027779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_revisions</td>\n",
       "      <td>-0.024701</td>\n",
       "      <td>0.024701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>top_contributor_frac</td>\n",
       "      <td>0.017444</td>\n",
       "      <td>0.017444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mean_edit_size</td>\n",
       "      <td>-0.009398</td>\n",
       "      <td>0.009398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature     score       abs\n",
       "5     mean_response_time  0.062737  0.062737\n",
       "6        page_talk_ratio -0.033946  0.033946\n",
       "1  frac_recent_revisions  0.030090  0.030090\n",
       "2            num_editors -0.027779  0.027779\n",
       "0          num_revisions -0.024701  0.024701\n",
       "3   top_contributor_frac  0.017444  0.017444\n",
       "4         mean_edit_size -0.009398  0.009398"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/lib/python3/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/christinedk/venv/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714721447700177"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 257,  789],\n",
       "       [ 230, 1088]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6810641627543035"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# talk lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(HOME+'features/talk_{}.json'.format(template),'rb') as f:\n",
    "    talk_pos = json.load(f)\n",
    "with open(HOME+'negative_features/talk_{}.json'.format(template),'rb') as f:\n",
    "    talk_neg = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_language(talk_feat):\n",
    "    if len(talk_feat) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        all_utts = pd.DataFrame(list(np.concatenate(list(talk_feat.values()))))\n",
    "        means = {'mean_'+key:val for key, val in all_utts.mean().items()}\n",
    "        std = {'std_'+key:val for key, val in all_utts.std().items()}\n",
    "        max_ = {'max_'+key:val for key, val in all_utts.max().items()}\n",
    "        features = {**means, **std, **max_}\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_lang_neg = pd.DataFrame([aggregate_language(d['talk_language']) for d in talk_neg])\n",
    "talk_lang_neg['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4282"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(talk_lang_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_lang_pos = pd.DataFrame([aggregate_language(d['talk_language']) for d in talk_pos])\n",
    "talk_lang_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5174"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(talk_lang_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_lang = pd.concat([talk_lang_neg,talk_lang_pos])\n",
    "labels = talk_lang['label']\n",
    "feat = talk_lang.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>max_politeness_markers_==Please==</td>\n",
       "      <td>-0.029337</td>\n",
       "      <td>0.029337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>max_politeness_markers_==Please_start==</td>\n",
       "      <td>-0.024005</td>\n",
       "      <td>0.024005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>max_politeness_markers_==Indirect_(greeting)==</td>\n",
       "      <td>-0.023797</td>\n",
       "      <td>0.023797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>max_politeness_markers_==1st_person_start==</td>\n",
       "      <td>-0.021296</td>\n",
       "      <td>0.021296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mean_politeness_markers_==2nd_person==</td>\n",
       "      <td>-0.020974</td>\n",
       "      <td>0.020974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>max_reply_depth</td>\n",
       "      <td>-0.020399</td>\n",
       "      <td>0.020399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>max_politeness_markers_==2nd_person==</td>\n",
       "      <td>-0.020345</td>\n",
       "      <td>0.020345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>max_politeness_markers_==Gratitude==</td>\n",
       "      <td>-0.020281</td>\n",
       "      <td>0.020281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>max_politeness_markers_==1st_person==</td>\n",
       "      <td>-0.019901</td>\n",
       "      <td>0.019901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mean_politeness_markers_==1st_person==</td>\n",
       "      <td>-0.018795</td>\n",
       "      <td>0.018795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           feature     score       abs\n",
       "44               max_politeness_markers_==Please== -0.029337  0.029337\n",
       "45         max_politeness_markers_==Please_start== -0.024005  0.024005\n",
       "58  max_politeness_markers_==Indirect_(greeting)== -0.023797  0.023797\n",
       "55     max_politeness_markers_==1st_person_start== -0.021296  0.021296\n",
       "12          mean_politeness_markers_==2nd_person== -0.020974  0.020974\n",
       "65                                 max_reply_depth -0.020399  0.020399\n",
       "56           max_politeness_markers_==2nd_person== -0.020345  0.020345\n",
       "51            max_politeness_markers_==Gratitude== -0.020281  0.020281\n",
       "54           max_politeness_markers_==1st_person== -0.019901  0.019901\n",
       "10          mean_politeness_markers_==1st_person== -0.018795  0.018795"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7417919120374664"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[727, 325],\n",
       "       [472, 840]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6782398062171983"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# editors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def aggregate_editor(editor_feat):\n",
    "    if len(editor_feat) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        all_utts = pd.DataFrame(editor_feat).drop('event_user_id',axis=1)\n",
    "        means = {'mean_'+key:val for key, val in all_utts.mean().items()}\n",
    "        std = {'std_'+key:val for key, val in all_utts.std().items()}\n",
    "        max_ = {'max_'+key:val for key, val in all_utts.max().items()}\n",
    "        features = {**means, **std, **max_}\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(HOME+'features/editors{}_v2.json'.format(template),'rb') as f:\n",
    "    editors_pos = json.load(f)\n",
    "    \n",
    "with open(HOME+'negative_features/editors{}_v2.json'.format(template),'rb') as f:\n",
    "    editors_neg = json.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "editor_neg = pd.DataFrame([aggregate_editor(d['editor']) for d in editors_neg])\n",
    "editor_neg['label'] = 0\n",
    "editor_pos = pd.DataFrame([aggregate_editor(d['editor']) for d in editors_pos])\n",
    "editor_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "len(editor_neg)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "len(editor_pos)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "editor_data = pd.concat([editor_neg,editor_pos])\n",
    "labels = editor_data['label']\n",
    "feat = editor_data.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# editor-editor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def aggregate(df):\n",
    "    means = {'mean_'+key:val for key, val in df.mean().items()}\n",
    "    std = {'std_'+key:val for key, val in df.std().items()}\n",
    "    max_ = {'max_'+key:val for key, val in df.max().items()}\n",
    "    features = {**means, **std, **max_}\n",
    "    return features\n",
    "\n",
    "def aggregate_collab(editor_feat):\n",
    "    if len(editor_feat['undirected']) == 0:\n",
    "        features = {}\n",
    "        \n",
    "    else:\n",
    "        directed = pd.DataFrame(editor_feat['directed']).drop(['event_user_id','event_user_id_r'],axis=1)\n",
    "        undirected = pd.DataFrame(editor_feat['undirected']).drop('pair',axis=1)\n",
    "\n",
    "        dir_features = aggregate(directed)\n",
    "        undir_features = aggregate(undirected)\n",
    "\n",
    "        features = {**dir_features,**undir_features}\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "collab_neg = pd.DataFrame([aggregate_collab(d['collaboration']) for d in editors_neg])\n",
    "collab_neg['label'] = 0\n",
    "collab_pos = pd.DataFrame([aggregate_collab(d['collaboration']) for d in editors_pos])\n",
    "collab_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "collab_data = pd.concat([editor_neg,editor_pos])\n",
    "labels = collab_data['label']\n",
    "feat = collab_data.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = article_data['label']\n",
    "\n",
    "feat = pd.concat([ds.reset_index(drop=True).drop('label',axis=1) \n",
    "                  for ds in [article_data,talk_vol,talk_lang,user_article_data]],axis=1) #editor_data,collab_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9456"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>contribution_frac_entropy</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.088496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>article_age_years</td>\n",
       "      <td>0.076672</td>\n",
       "      <td>0.076672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>max_frac_page_edits</td>\n",
       "      <td>-0.073533</td>\n",
       "      <td>0.073533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>frac_page_edits_ent</td>\n",
       "      <td>0.070744</td>\n",
       "      <td>0.070744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>top_contributor_frac</td>\n",
       "      <td>-0.070540</td>\n",
       "      <td>0.070540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>frac_anon_revisions</td>\n",
       "      <td>0.070309</td>\n",
       "      <td>0.070309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>std_frac_page_edits</td>\n",
       "      <td>-0.068979</td>\n",
       "      <td>0.068979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>frac_recent_revisions</td>\n",
       "      <td>-0.065640</td>\n",
       "      <td>0.065640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>mean_frac_page_edits</td>\n",
       "      <td>-0.061991</td>\n",
       "      <td>0.061991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>num_editors</td>\n",
       "      <td>0.058880</td>\n",
       "      <td>0.058880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature     score       abs\n",
       "12   contribution_frac_entropy  0.088496  0.088496\n",
       "2            article_age_years  0.076672  0.076672\n",
       "109        max_frac_page_edits -0.073533  0.073533\n",
       "112        frac_page_edits_ent  0.070744  0.070744\n",
       "9         top_contributor_frac -0.070540  0.070540\n",
       "10         frac_anon_revisions  0.070309  0.070309\n",
       "101        std_frac_page_edits -0.068979  0.068979\n",
       "16       frac_recent_revisions -0.065640  0.065640\n",
       "93        mean_frac_page_edits -0.061991  0.061991\n",
       "17                 num_editors  0.058880  0.058880"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/lib/python3/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/christinedk/venv/lib/python3.7/site-packages/ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)#,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7398213612571471"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[756, 342],\n",
       "       [478, 788]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.657762938230384"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thoughts:\n",
    "\n",
    "# article:\n",
    "# comparing to same pages means some features are less relevant; eg. num_editors, mean edit_size, top_contributor_frac, etc\n",
    "# recency features should be more important \n",
    "#     - calculate all features for recent revisions only as well?\n",
    "\n",
    "\n",
    "# user-article\n",
    "# empty for some negatives? sample page': 189559,'date': '2003-02-28 16:09:01'\n",
    "# revert features are incorrect, need to re-export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
