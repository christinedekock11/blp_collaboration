{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "HOME = '/srv/home/christinedk/wp_internship/'\n",
    "DATA_DIR = HOME + 'data/'\n",
    "sys.path.append(HOME + 'collaboration/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/least_angle.py:1097: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/least_angle.py:1344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/least_angle.py:1480: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/randomized_l1.py:320: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/randomized_l1.py:580: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=None,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from math import log2\n",
    "from utils import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "template='advert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(HOME+'features/activity_{}.json'.format(template),'rb') as f:\n",
    "    features_pos = json.load(f)\n",
    "with open(HOME+'negative_features/activity_{}.json'.format(template),'rb') as f:\n",
    "    features_neg = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7570"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6045"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_features_neg = pd.DataFrame([d['article'] for d in features_neg])\n",
    "article_features_neg['label'] = 0\n",
    "article_features_pos = pd.DataFrame([d['article'] for d in features_pos])\n",
    "article_features_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data = pd.concat([article_features_neg, article_features_pos])\n",
    "labels = article_data['label']\n",
    "feat = article_data.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13615"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>frac_recent_revisions</td>\n",
       "      <td>0.305192</td>\n",
       "      <td>0.305192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>concentration_ratio</td>\n",
       "      <td>0.133609</td>\n",
       "      <td>0.133609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>recent_response_time</td>\n",
       "      <td>0.125896</td>\n",
       "      <td>0.125896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>recent_edit_size</td>\n",
       "      <td>0.108532</td>\n",
       "      <td>0.108532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>contribution_frac_entropy</td>\n",
       "      <td>-0.098823</td>\n",
       "      <td>0.098823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>edit_size</td>\n",
       "      <td>0.094759</td>\n",
       "      <td>0.094759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>time_to_respond</td>\n",
       "      <td>0.083943</td>\n",
       "      <td>0.083943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>top_contributor_frac</td>\n",
       "      <td>0.077974</td>\n",
       "      <td>0.077974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_revisions</td>\n",
       "      <td>-0.046778</td>\n",
       "      <td>0.046778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>frac_anon_revisions</td>\n",
       "      <td>-0.046518</td>\n",
       "      <td>0.046518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature     score       abs\n",
       "8       frac_recent_revisions  0.305192  0.305192\n",
       "11        concentration_ratio  0.133609  0.133609\n",
       "14       recent_response_time  0.125896  0.125896\n",
       "13           recent_edit_size  0.108532  0.108532\n",
       "12  contribution_frac_entropy -0.098823  0.098823\n",
       "0                   edit_size  0.094759  0.094759\n",
       "1             time_to_respond  0.083943  0.083943\n",
       "9        top_contributor_frac  0.077974  0.077974\n",
       "6               num_revisions -0.046778  0.046778\n",
       "10        frac_anon_revisions -0.046518  0.046518"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = {'solver':'lbfgs','max_iter':10000,'C':10000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/lib/python3/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/christinedk/venv/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7316068312644818"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1040,  443],\n",
       "       [ 724, 1197]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6722830665543387"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_features(article_users):\n",
    "    if len(article_users) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        article_users = pd.DataFrame(article_users).drop('event_user_id',axis=1)\n",
    "        means = {'mean_'+key:val for key, val in article_users.mean().items()}\n",
    "        std = {'std_'+key:val for key, val in article_users.std().items()}\n",
    "        max_ = {'max_'+key:val for key, val in article_users.max().items()}\n",
    "        ent = {'frac_page_edits_ent': entropy(article_users.frac_page_edits)}\n",
    "        features = {**means, **std, **max_, **ent}\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_article_features_pos = pd.DataFrame([aggregate_features(d['user_article']) \n",
    "                                          for d in features_pos])\n",
    "user_article_features_neg = pd.DataFrame([aggregate_features(d['user_article']) \n",
    "                                          for d in features_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_article_features_pos['label'] = 1\n",
    "user_article_features_neg['label'] = 0\n",
    "\n",
    "user_article_data = pd.concat([user_article_features_neg,user_article_features_pos])\n",
    "labels = user_article_data['label']\n",
    "feat = user_article_data.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean_frac_page_edits</td>\n",
       "      <td>0.216113</td>\n",
       "      <td>0.216113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>frac_page_edits_ent</td>\n",
       "      <td>-0.113989</td>\n",
       "      <td>0.113989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean_time_to_respond</td>\n",
       "      <td>0.086815</td>\n",
       "      <td>0.086815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>max_frac_page_edits</td>\n",
       "      <td>0.085800</td>\n",
       "      <td>0.085800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean_edit_size</td>\n",
       "      <td>0.084020</td>\n",
       "      <td>0.084020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>std_frac_page_edits</td>\n",
       "      <td>0.080455</td>\n",
       "      <td>0.080455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mean_time_responded_to</td>\n",
       "      <td>0.079513</td>\n",
       "      <td>0.079513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>std_time_to_respond</td>\n",
       "      <td>0.066997</td>\n",
       "      <td>0.066997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>std_time_responded_to</td>\n",
       "      <td>0.056178</td>\n",
       "      <td>0.056178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>max_num_edits</td>\n",
       "      <td>-0.052788</td>\n",
       "      <td>0.052788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature     score       abs\n",
       "5     mean_frac_page_edits  0.216113  0.216113\n",
       "24     frac_page_edits_ent -0.113989  0.113989\n",
       "2     mean_time_to_respond  0.086815  0.086815\n",
       "21     max_frac_page_edits  0.085800  0.085800\n",
       "0           mean_edit_size  0.084020  0.084020\n",
       "13     std_frac_page_edits  0.080455  0.080455\n",
       "3   mean_time_responded_to  0.079513  0.079513\n",
       "10     std_time_to_respond  0.066997  0.066997\n",
       "11   std_time_responded_to  0.056178  0.056178\n",
       "20           max_num_edits -0.052788  0.052788"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6397163865546218"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 845,  655],\n",
       "       [ 739, 1165]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6256713211600429"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# talk vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(HOME+'features/talk_{}.json'.format(template),'rb') as f:\n",
    "    talk_pos = json.load(f)\n",
    "with open(HOME+'negative_features/talk_{}.json'.format(template),'rb') as f:\n",
    "    talk_neg = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_vol_neg = pd.DataFrame([d['talk_volume'] for d in talk_neg])\n",
    "talk_vol_neg['label'] = 0\n",
    "talk_vol_pos = pd.DataFrame([d['talk_volume'] for d in talk_pos])\n",
    "talk_vol_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_vol = pd.concat([talk_vol_neg,talk_vol_pos])\n",
    "labels = talk_vol['label']\n",
    "feat = talk_vol.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean_response_time</td>\n",
       "      <td>0.064857</td>\n",
       "      <td>0.064857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frac_recent_revisions</td>\n",
       "      <td>0.030878</td>\n",
       "      <td>0.030878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num_editors</td>\n",
       "      <td>-0.026086</td>\n",
       "      <td>0.026086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mean_edit_size</td>\n",
       "      <td>-0.025699</td>\n",
       "      <td>0.025699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_revisions</td>\n",
       "      <td>-0.021082</td>\n",
       "      <td>0.021082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>page_talk_ratio</td>\n",
       "      <td>-0.019187</td>\n",
       "      <td>0.019187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>top_contributor_frac</td>\n",
       "      <td>0.012608</td>\n",
       "      <td>0.012608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature     score       abs\n",
       "5     mean_response_time  0.064857  0.064857\n",
       "1  frac_recent_revisions  0.030878  0.030878\n",
       "2            num_editors -0.026086  0.026086\n",
       "4         mean_edit_size -0.025699  0.025699\n",
       "0          num_revisions -0.021082  0.021082\n",
       "6        page_talk_ratio -0.019187  0.019187\n",
       "3   top_contributor_frac  0.012608  0.012608"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/lib/python3/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/christinedk/venv/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.549895324250742"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 196, 1336],\n",
       "       [ 174, 1698]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6922136159804322"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# talk lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(HOME+'features/talk_{}.json'.format(template),'rb') as f:\n",
    "    talk_pos = json.load(f)\n",
    "with open(HOME+'negative_features/talk_{}.json'.format(template),'rb') as f:\n",
    "    talk_neg = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_language(talk_feat):\n",
    "    if len(talk_feat) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        all_utts = pd.DataFrame(list(np.concatenate(list(talk_feat.values()))))\n",
    "        means = {'mean_'+key:val for key, val in all_utts.mean().items()}\n",
    "        std = {'std_'+key:val for key, val in all_utts.std().items()}\n",
    "        max_ = {'max_'+key:val for key, val in all_utts.max().items()}\n",
    "        features = {**means, **std, **max_}\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_lang_neg = pd.DataFrame([aggregate_language(d['talk_language']) for d in talk_neg])\n",
    "talk_lang_neg['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6045"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(talk_lang_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_lang_pos = pd.DataFrame([aggregate_language(d['talk_language']) for d in talk_pos])\n",
    "talk_lang_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7570"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(talk_lang_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_lang = pd.concat([talk_lang_neg,talk_lang_pos])\n",
    "labels = talk_lang['label']\n",
    "feat = talk_lang.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>max_reply_depth</td>\n",
       "      <td>-0.033367</td>\n",
       "      <td>0.033367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>max_politeness_markers_==Gratitude==</td>\n",
       "      <td>-0.031908</td>\n",
       "      <td>0.031908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>max_politeness_markers_==1st_person_start==</td>\n",
       "      <td>-0.030567</td>\n",
       "      <td>0.030567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>max_politeness_markers_==Please==</td>\n",
       "      <td>-0.029829</td>\n",
       "      <td>0.029829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mean_reply_depth</td>\n",
       "      <td>-0.029532</td>\n",
       "      <td>0.029532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>max_politeness_markers_==HASHEDGE==</td>\n",
       "      <td>-0.029158</td>\n",
       "      <td>0.029158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>max_politeness_markers_==2nd_person==</td>\n",
       "      <td>-0.028984</td>\n",
       "      <td>0.028984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>max_politeness_markers_==1st_person==</td>\n",
       "      <td>-0.028632</td>\n",
       "      <td>0.028632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>max_politeness_markers_==Please_start==</td>\n",
       "      <td>-0.027598</td>\n",
       "      <td>0.027598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>max_politeness_markers_==Hedges==</td>\n",
       "      <td>-0.026818</td>\n",
       "      <td>0.026818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        feature     score       abs\n",
       "65                              max_reply_depth -0.033367  0.033367\n",
       "51         max_politeness_markers_==Gratitude== -0.031908  0.031908\n",
       "55  max_politeness_markers_==1st_person_start== -0.030567  0.030567\n",
       "44            max_politeness_markers_==Please== -0.029829  0.029829\n",
       "21                             mean_reply_depth -0.029532  0.029532\n",
       "46          max_politeness_markers_==HASHEDGE== -0.029158  0.029158\n",
       "56        max_politeness_markers_==2nd_person== -0.028984  0.028984\n",
       "54        max_politeness_markers_==1st_person== -0.028632  0.028632\n",
       "45      max_politeness_markers_==Please_start== -0.027598  0.027598\n",
       "48            max_politeness_markers_==Hedges== -0.026818  0.026818"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48331837758969587"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  76, 1406],\n",
       "       [  88, 1834]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.710577295621852"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# editors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def aggregate_editor(editor_feat):\n",
    "    if len(editor_feat) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        all_utts = pd.DataFrame(editor_feat).drop('event_user_id',axis=1)\n",
    "        means = {'mean_'+key:val for key, val in all_utts.mean().items()}\n",
    "        std = {'std_'+key:val for key, val in all_utts.std().items()}\n",
    "        max_ = {'max_'+key:val for key, val in all_utts.max().items()}\n",
    "        features = {**means, **std, **max_}\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(HOME+'features/editors{}_v2.json'.format(template),'rb') as f:\n",
    "    editors_pos = json.load(f)\n",
    "    \n",
    "with open(HOME+'negative_features/editors{}_v2.json'.format(template),'rb') as f:\n",
    "    editors_neg = json.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "editor_neg = pd.DataFrame([aggregate_editor(d['editor']) for d in editors_neg])\n",
    "editor_neg['label'] = 0\n",
    "editor_pos = pd.DataFrame([aggregate_editor(d['editor']) for d in editors_pos])\n",
    "editor_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "len(editor_neg)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "len(editor_pos)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "editor_data = pd.concat([editor_neg,editor_pos])\n",
    "labels = editor_data['label']\n",
    "feat = editor_data.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# editor-editor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def aggregate(df):\n",
    "    means = {'mean_'+key:val for key, val in df.mean().items()}\n",
    "    std = {'std_'+key:val for key, val in df.std().items()}\n",
    "    max_ = {'max_'+key:val for key, val in df.max().items()}\n",
    "    features = {**means, **std, **max_}\n",
    "    return features\n",
    "\n",
    "def aggregate_collab(editor_feat):\n",
    "    if len(editor_feat['undirected']) == 0:\n",
    "        features = {}\n",
    "        \n",
    "    else:\n",
    "        directed = pd.DataFrame(editor_feat['directed']).drop(['event_user_id','event_user_id_r'],axis=1)\n",
    "        undirected = pd.DataFrame(editor_feat['undirected']).drop('pair',axis=1)\n",
    "\n",
    "        dir_features = aggregate(directed)\n",
    "        undir_features = aggregate(undirected)\n",
    "\n",
    "        features = {**dir_features,**undir_features}\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "collab_neg = pd.DataFrame([aggregate_collab(d['collaboration']) for d in editors_neg])\n",
    "collab_neg['label'] = 0\n",
    "collab_pos = pd.DataFrame([aggregate_collab(d['collaboration']) for d in editors_pos])\n",
    "collab_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "collab_data = pd.concat([editor_neg,editor_pos])\n",
    "labels = collab_data['label']\n",
    "feat = collab_data.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = article_data['label']\n",
    "\n",
    "feat = pd.concat([ds.reset_index(drop=True).drop('label',axis=1) \n",
    "                  for ds in [article_data,talk_vol,talk_lang,user_article_data]],axis=1) #editor_data,collab_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13615"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>article_age_years</td>\n",
       "      <td>0.068934</td>\n",
       "      <td>0.068934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>contribution_frac_entropy</td>\n",
       "      <td>0.065030</td>\n",
       "      <td>0.065030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>frac_anon_revisions</td>\n",
       "      <td>0.063187</td>\n",
       "      <td>0.063187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>max_frac_page_edits</td>\n",
       "      <td>-0.062240</td>\n",
       "      <td>0.062240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>std_frac_page_edits</td>\n",
       "      <td>-0.056771</td>\n",
       "      <td>0.056771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>top_contributor_frac</td>\n",
       "      <td>-0.056593</td>\n",
       "      <td>0.056593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>recent_response_time</td>\n",
       "      <td>0.055798</td>\n",
       "      <td>0.055798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>frac_recent_revisions</td>\n",
       "      <td>-0.051686</td>\n",
       "      <td>0.051686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>time_to_respond</td>\n",
       "      <td>0.048907</td>\n",
       "      <td>0.048907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>frac_page_edits_ent</td>\n",
       "      <td>0.044784</td>\n",
       "      <td>0.044784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature     score       abs\n",
       "2            article_age_years  0.068934  0.068934\n",
       "12   contribution_frac_entropy  0.065030  0.065030\n",
       "10         frac_anon_revisions  0.063187  0.063187\n",
       "109        max_frac_page_edits -0.062240  0.062240\n",
       "101        std_frac_page_edits -0.056771  0.056771\n",
       "9         top_contributor_frac -0.056593  0.056593\n",
       "14        recent_response_time  0.055798  0.055798\n",
       "16       frac_recent_revisions -0.051686  0.051686\n",
       "1              time_to_respond  0.048907  0.048907\n",
       "112        frac_page_edits_ent  0.044784  0.044784"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/lib/python3/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/christinedk/venv/lib/python3.7/site-packages/ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)#,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7230931550951848"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 996,  508],\n",
       "       [ 684, 1216]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6710816777041944"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thoughts:\n",
    "\n",
    "# article:\n",
    "# comparing to same pages means some features are less relevant; eg. num_editors, mean edit_size, top_contributor_frac, etc\n",
    "# recency features should be more important \n",
    "#     - calculate all features for recent revisions only as well?\n",
    "\n",
    "\n",
    "# user-article\n",
    "# empty for some negatives? sample page': 189559,'date': '2003-02-28 16:09:01'\n",
    "# revert features are incorrect, need to re-export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
