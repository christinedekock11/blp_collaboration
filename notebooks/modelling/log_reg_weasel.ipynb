{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "HOME = '/srv/home/christinedk/wp_internship/'\n",
    "DATA_DIR = HOME + 'data/'\n",
    "sys.path.append(HOME + 'collaboration/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/least_angle.py:1097: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/least_angle.py:1344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/least_angle.py:1480: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/randomized_l1.py:320: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "/usr/lib/python3/dist-packages/sklearn/linear_model/randomized_l1.py:580: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=None,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from math import log2\n",
    "from utils import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(HOME+'features/activity_weasel.json','rb') as f:\n",
    "    features_pos = json.load(f)\n",
    "with open(HOME+'negative_features/activity_weasel.json','rb') as f:\n",
    "    features_neg = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1322"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1187"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_features_neg = pd.DataFrame([d['article'] for d in features_neg])\n",
    "article_features_neg['label'] = 0\n",
    "article_features_pos = pd.DataFrame([d['article'] for d in features_pos])\n",
    "article_features_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data = pd.concat([article_features_neg, article_features_pos])\n",
    "labels = article_data['label']\n",
    "feat = article_data.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2509"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>frac_recent_revisions</td>\n",
       "      <td>0.256553</td>\n",
       "      <td>0.256553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>recent_edit_size</td>\n",
       "      <td>0.111633</td>\n",
       "      <td>0.111633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>concentration_ratio</td>\n",
       "      <td>0.109498</td>\n",
       "      <td>0.109498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>recent_response_time</td>\n",
       "      <td>0.076485</td>\n",
       "      <td>0.076485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>contribution_frac_entropy</td>\n",
       "      <td>-0.073308</td>\n",
       "      <td>0.073308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>time_to_respond</td>\n",
       "      <td>0.070563</td>\n",
       "      <td>0.070563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>top_contributor_frac</td>\n",
       "      <td>0.058334</td>\n",
       "      <td>0.058334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>edit_size</td>\n",
       "      <td>0.051861</td>\n",
       "      <td>0.051861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num_editors</td>\n",
       "      <td>-0.041554</td>\n",
       "      <td>0.041554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_revisions</td>\n",
       "      <td>-0.041465</td>\n",
       "      <td>0.041465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature     score       abs\n",
       "8       frac_recent_revisions  0.256553  0.256553\n",
       "13           recent_edit_size  0.111633  0.111633\n",
       "11        concentration_ratio  0.109498  0.109498\n",
       "14       recent_response_time  0.076485  0.076485\n",
       "12  contribution_frac_entropy -0.073308  0.073308\n",
       "1             time_to_respond  0.070563  0.070563\n",
       "9        top_contributor_frac  0.058334  0.058334\n",
       "0                   edit_size  0.051861  0.051861\n",
       "7                 num_editors -0.041554  0.041554\n",
       "6               num_revisions -0.041465  0.041465"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = {'solver':'lbfgs','max_iter':10000,'C':10000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/lib/python3/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/christinedk/venv/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69870463155322"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[221,  73],\n",
       "       [161, 173]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.596551724137931"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_features(article_users):\n",
    "    if len(article_users) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        article_users = pd.DataFrame(article_users).drop('event_user_id',axis=1)\n",
    "        means = {'mean_'+key:val for key, val in article_users.mean().items()}\n",
    "        std = {'std_'+key:val for key, val in article_users.std().items()}\n",
    "        max_ = {'max_'+key:val for key, val in article_users.max().items()}\n",
    "        ent = {'frac_page_edits_ent': entropy(article_users.frac_page_edits)}\n",
    "        features = {**means, **std, **max_, **ent}\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_article_features_pos = pd.DataFrame([aggregate_features(d['user_article']) \n",
    "                                          for d in features_pos])\n",
    "user_article_features_neg = pd.DataFrame([aggregate_features(d['user_article']) \n",
    "                                          for d in features_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_article_features_pos['label'] = 1\n",
    "user_article_features_neg['label'] = 0\n",
    "\n",
    "user_article_data = pd.concat([user_article_features_neg,user_article_features_pos])\n",
    "labels = user_article_data['label']\n",
    "feat = user_article_data.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean_frac_page_edits</td>\n",
       "      <td>0.168689</td>\n",
       "      <td>0.168689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>frac_page_edits_ent</td>\n",
       "      <td>-0.088316</td>\n",
       "      <td>0.088316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>std_num_edits</td>\n",
       "      <td>-0.067213</td>\n",
       "      <td>0.067213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean_time_to_respond</td>\n",
       "      <td>0.066158</td>\n",
       "      <td>0.066158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mean_time_responded_to</td>\n",
       "      <td>0.063776</td>\n",
       "      <td>0.063776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>max_frac_page_edits</td>\n",
       "      <td>0.063415</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>std_frac_page_edits</td>\n",
       "      <td>0.063340</td>\n",
       "      <td>0.063340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mean_num_edits</td>\n",
       "      <td>-0.057230</td>\n",
       "      <td>0.057230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>std_time_to_respond</td>\n",
       "      <td>0.049629</td>\n",
       "      <td>0.049629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>std_time_responded_to</td>\n",
       "      <td>0.045661</td>\n",
       "      <td>0.045661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature     score       abs\n",
       "5     mean_frac_page_edits  0.168689  0.168689\n",
       "24     frac_page_edits_ent -0.088316  0.088316\n",
       "12           std_num_edits -0.067213  0.067213\n",
       "2     mean_time_to_respond  0.066158  0.066158\n",
       "3   mean_time_responded_to  0.063776  0.063776\n",
       "21     max_frac_page_edits  0.063415  0.063415\n",
       "13     std_frac_page_edits  0.063340  0.063340\n",
       "4           mean_num_edits -0.057230  0.057230\n",
       "10     std_time_to_respond  0.049629  0.049629\n",
       "11   std_time_responded_to  0.045661  0.045661"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5541461412151067"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[176, 104],\n",
       "       [192, 156]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5131578947368421"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# talk vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(HOME+'features/talk_weasel.json','rb') as f:\n",
    "    talk_pos = json.load(f)\n",
    "with open(HOME+'negative_features/talk_weasel.json','rb') as f:\n",
    "    talk_neg = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_vol_neg = pd.DataFrame([d['talk_volume'] for d in talk_neg])\n",
    "talk_vol_neg['label'] = 0\n",
    "talk_vol_pos = pd.DataFrame([d['talk_volume'] for d in talk_pos])\n",
    "talk_vol_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_vol = pd.concat([talk_vol_neg,talk_vol_pos])\n",
    "labels = talk_vol['label']\n",
    "feat = talk_vol.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frac_recent_revisions</td>\n",
       "      <td>0.066025</td>\n",
       "      <td>0.066025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean_response_time</td>\n",
       "      <td>0.058586</td>\n",
       "      <td>0.058586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>top_contributor_frac</td>\n",
       "      <td>0.030387</td>\n",
       "      <td>0.030387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num_editors</td>\n",
       "      <td>-0.029847</td>\n",
       "      <td>0.029847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_revisions</td>\n",
       "      <td>-0.021363</td>\n",
       "      <td>0.021363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>page_talk_ratio</td>\n",
       "      <td>-0.019589</td>\n",
       "      <td>0.019589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mean_edit_size</td>\n",
       "      <td>-0.007681</td>\n",
       "      <td>0.007681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature     score       abs\n",
       "1  frac_recent_revisions  0.066025  0.066025\n",
       "5     mean_response_time  0.058586  0.058586\n",
       "3   top_contributor_frac  0.030387  0.030387\n",
       "2            num_editors -0.029847  0.029847\n",
       "0          num_revisions -0.021363  0.021363\n",
       "6        page_talk_ratio -0.019589  0.019589\n",
       "4         mean_edit_size -0.007681  0.007681"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/lib/python3/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/christinedk/venv/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5344075193017791"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[104, 193],\n",
       "       [100, 231]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6119205298013244"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# talk lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(HOME+'features/talk_weasel.json','rb') as f:\n",
    "    talk_pos = json.load(f)\n",
    "with open(HOME+'negative_features/talk_weasel.json','rb') as f:\n",
    "    talk_neg = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_language(talk_feat):\n",
    "    if len(talk_feat) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        all_utts = pd.DataFrame(list(np.concatenate(list(talk_feat.values()))))\n",
    "        means = {'mean_'+key:val for key, val in all_utts.mean().items()}\n",
    "        std = {'std_'+key:val for key, val in all_utts.std().items()}\n",
    "        max_ = {'max_'+key:val for key, val in all_utts.max().items()}\n",
    "        features = {**means, **std, **max_}\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_lang_neg = pd.DataFrame([aggregate_language(d['talk_language']) for d in talk_neg])\n",
    "talk_lang_neg['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1187"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(talk_lang_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_lang_pos = pd.DataFrame([aggregate_language(d['talk_language']) for d in talk_pos])\n",
    "talk_lang_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1322"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(talk_lang_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_lang = pd.concat([talk_lang_neg,talk_lang_pos])\n",
    "labels = talk_lang['label']\n",
    "feat = talk_lang.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mean_politeness_markers_==1st_person_start==</td>\n",
       "      <td>-0.030833</td>\n",
       "      <td>0.030833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>max_politeness_markers_==Indirect_(greeting)==</td>\n",
       "      <td>-0.030296</td>\n",
       "      <td>0.030296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mean_politeness_markers_==1st_person==</td>\n",
       "      <td>-0.025049</td>\n",
       "      <td>0.025049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>max_politeness_markers_==Please==</td>\n",
       "      <td>-0.023966</td>\n",
       "      <td>0.023966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>max_politeness_markers_==Please_start==</td>\n",
       "      <td>-0.022454</td>\n",
       "      <td>0.022454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mean_politeness_markers_==Indirect_(greeting)==</td>\n",
       "      <td>-0.022230</td>\n",
       "      <td>0.022230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>max_politeness_markers_==HASHEDGE==</td>\n",
       "      <td>-0.019711</td>\n",
       "      <td>0.019711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>std_politeness_markers_==Indirect_(greeting)==</td>\n",
       "      <td>-0.019401</td>\n",
       "      <td>0.019401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>max_politeness_markers_==1st_person_start==</td>\n",
       "      <td>-0.018589</td>\n",
       "      <td>0.018589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>max_politeness_markers_==Hedges==</td>\n",
       "      <td>-0.016511</td>\n",
       "      <td>0.016511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            feature     score       abs\n",
       "11     mean_politeness_markers_==1st_person_start== -0.030833  0.030833\n",
       "58   max_politeness_markers_==Indirect_(greeting)== -0.030296  0.030296\n",
       "10           mean_politeness_markers_==1st_person== -0.025049  0.025049\n",
       "44                max_politeness_markers_==Please== -0.023966  0.023966\n",
       "45          max_politeness_markers_==Please_start== -0.022454  0.022454\n",
       "14  mean_politeness_markers_==Indirect_(greeting)== -0.022230  0.022230\n",
       "46              max_politeness_markers_==HASHEDGE== -0.019711  0.019711\n",
       "36   std_politeness_markers_==Indirect_(greeting)== -0.019401  0.019401\n",
       "55      max_politeness_markers_==1st_person_start== -0.018589  0.018589\n",
       "48                max_politeness_markers_==Hedges== -0.016511  0.016511"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42005538255550934"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 43, 268],\n",
       "       [ 62, 255]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6071428571428572"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# editors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_editor(editor_feat):\n",
    "    if len(editor_feat) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        all_utts = pd.DataFrame(editor_feat).drop('event_user_id',axis=1)\n",
    "        means = {'mean_'+key:val for key, val in all_utts.mean().items()}\n",
    "        std = {'std_'+key:val for key, val in all_utts.std().items()}\n",
    "        max_ = {'max_'+key:val for key, val in all_utts.max().items()}\n",
    "        features = {**means, **std, **max_}\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(HOME+'features/editorsweasel_dd.json','rb') as f:\n",
    "    editors_pos = json.load(f)\n",
    "    \n",
    "with open(HOME+'negative_features/editorsweasel_v2.json','rb') as f:\n",
    "    editors_neg = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('/srv/home/christinedk/wp_internship/data/negative_labels/weasel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "editor_neg = pd.DataFrame([aggregate_editor(d['editor']) for d in editors_neg])\n",
    "editor_neg['label'] = 0\n",
    "editor_pos = pd.DataFrame([aggregate_editor(d['editor']) for d in editors_pos])\n",
    "editor_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1187"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(editor_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1322"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(editor_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "editor_data = pd.concat([editor_neg,editor_pos])\n",
    "labels = editor_data['label']\n",
    "feat = editor_data.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>max_contribution_frac_entropy</td>\n",
       "      <td>-0.097824</td>\n",
       "      <td>0.097824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>max_num_groups</td>\n",
       "      <td>-0.073245</td>\n",
       "      <td>0.073245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mean_contribution_frac_entropy</td>\n",
       "      <td>-0.057362</td>\n",
       "      <td>0.057362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>max_num_curr_blocks</td>\n",
       "      <td>-0.048621</td>\n",
       "      <td>0.048621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>std_contribution_frac_entropy</td>\n",
       "      <td>0.045715</td>\n",
       "      <td>0.045715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>max_num_past_blocks</td>\n",
       "      <td>-0.039697</td>\n",
       "      <td>0.039697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>std_num_past_blocks</td>\n",
       "      <td>-0.037692</td>\n",
       "      <td>0.037692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>max_talk_article_ratio</td>\n",
       "      <td>-0.033751</td>\n",
       "      <td>0.033751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>max_time_since_registration</td>\n",
       "      <td>-0.033707</td>\n",
       "      <td>0.033707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>max_num_reverts_of_others</td>\n",
       "      <td>-0.029298</td>\n",
       "      <td>0.029298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature     score       abs\n",
       "29   max_contribution_frac_entropy -0.097824  0.097824\n",
       "20                  max_num_groups -0.073245  0.073245\n",
       "9   mean_contribution_frac_entropy -0.057362  0.057362\n",
       "24             max_num_curr_blocks -0.048621  0.048621\n",
       "19   std_contribution_frac_entropy  0.045715  0.045715\n",
       "23             max_num_past_blocks -0.039697  0.039697\n",
       "13             std_num_past_blocks -0.037692  0.037692\n",
       "28          max_talk_article_ratio -0.033751  0.033751\n",
       "27     max_time_since_registration -0.033707  0.033707\n",
       "26       max_num_reverts_of_others -0.029298  0.029298"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5345284278146248"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[150, 112],\n",
       "       [186, 180]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5471124620060791"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# editor-editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(df):\n",
    "    means = {'mean_'+key:val for key, val in df.mean().items()}\n",
    "    std = {'std_'+key:val for key, val in df.std().items()}\n",
    "    max_ = {'max_'+key:val for key, val in df.max().items()}\n",
    "    features = {**means, **std, **max_}\n",
    "    return features\n",
    "\n",
    "def aggregate_collab(editor_feat):\n",
    "    if len(editor_feat['undirected']) == 0:\n",
    "        features = {}\n",
    "        \n",
    "    else:\n",
    "        directed = pd.DataFrame(editor_feat['directed']).drop(['event_user_id','event_user_id_r'],axis=1)\n",
    "        undirected = pd.DataFrame(editor_feat['undirected']).drop('pair',axis=1)\n",
    "\n",
    "        dir_features = aggregate(directed)\n",
    "        undir_features = aggregate(undirected)\n",
    "\n",
    "        features = {**dir_features,**undir_features}\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collab_neg = pd.DataFrame([aggregate_collab(d['collaboration']) for d in editors_neg])\n",
    "collab_neg['label'] = 0\n",
    "collab_pos = pd.DataFrame([aggregate_collab(d['collaboration']) for d in editors_pos])\n",
    "collab_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab_data = pd.concat([editor_neg,editor_pos])\n",
    "labels = collab_data['label']\n",
    "feat = collab_data.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>max_contribution_frac_entropy</td>\n",
       "      <td>-0.097824</td>\n",
       "      <td>0.097824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>max_num_groups</td>\n",
       "      <td>-0.073245</td>\n",
       "      <td>0.073245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mean_contribution_frac_entropy</td>\n",
       "      <td>-0.057362</td>\n",
       "      <td>0.057362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>max_num_curr_blocks</td>\n",
       "      <td>-0.048621</td>\n",
       "      <td>0.048621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>std_contribution_frac_entropy</td>\n",
       "      <td>0.045715</td>\n",
       "      <td>0.045715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>max_num_past_blocks</td>\n",
       "      <td>-0.039697</td>\n",
       "      <td>0.039697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>std_num_past_blocks</td>\n",
       "      <td>-0.037692</td>\n",
       "      <td>0.037692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>max_talk_article_ratio</td>\n",
       "      <td>-0.033751</td>\n",
       "      <td>0.033751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>max_time_since_registration</td>\n",
       "      <td>-0.033707</td>\n",
       "      <td>0.033707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>max_num_reverts_of_others</td>\n",
       "      <td>-0.029298</td>\n",
       "      <td>0.029298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature     score       abs\n",
       "29   max_contribution_frac_entropy -0.097824  0.097824\n",
       "20                  max_num_groups -0.073245  0.073245\n",
       "9   mean_contribution_frac_entropy -0.057362  0.057362\n",
       "24             max_num_curr_blocks -0.048621  0.048621\n",
       "19   std_contribution_frac_entropy  0.045715  0.045715\n",
       "23             max_num_past_blocks -0.039697  0.039697\n",
       "13             std_num_past_blocks -0.037692  0.037692\n",
       "28          max_talk_article_ratio -0.033751  0.033751\n",
       "27     max_time_since_registration -0.033707  0.033707\n",
       "26       max_num_reverts_of_others -0.029298  0.029298"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5266559129967232"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[108, 201],\n",
       "       [110, 209]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5733882030178327"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = article_data['label']\n",
    "\n",
    "feat = pd.concat([ds.reset_index(drop=True).drop('label',axis=1) \n",
    "                  for ds in [article_data,talk_vol,talk_lang,user_article_data,editor_data,collab_data]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2509"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>recent_edit_size</td>\n",
       "      <td>0.072737</td>\n",
       "      <td>0.072737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num_editors</td>\n",
       "      <td>0.070929</td>\n",
       "      <td>0.070929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>num_editors</td>\n",
       "      <td>0.066050</td>\n",
       "      <td>0.066050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>contribution_frac_entropy</td>\n",
       "      <td>0.065525</td>\n",
       "      <td>0.065525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_revisions</td>\n",
       "      <td>0.061432</td>\n",
       "      <td>0.061432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>curr_size</td>\n",
       "      <td>0.060503</td>\n",
       "      <td>0.060503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>last_edit_size</td>\n",
       "      <td>0.060503</td>\n",
       "      <td>0.060503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>frac_page_edits_ent</td>\n",
       "      <td>0.055904</td>\n",
       "      <td>0.055904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>num_revisions</td>\n",
       "      <td>0.050276</td>\n",
       "      <td>0.050276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>std_next_edit_size</td>\n",
       "      <td>0.048378</td>\n",
       "      <td>0.048378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature     score       abs\n",
       "13            recent_edit_size  0.072737  0.072737\n",
       "7                  num_editors  0.070929  0.070929\n",
       "17                 num_editors  0.066050  0.066050\n",
       "12   contribution_frac_entropy  0.065525  0.065525\n",
       "6                num_revisions  0.061432  0.061432\n",
       "3                    curr_size  0.060503  0.060503\n",
       "5               last_edit_size  0.060503  0.060503\n",
       "112        frac_page_edits_ent  0.055904  0.055904\n",
       "15               num_revisions  0.050276  0.050276\n",
       "97          std_next_edit_size  0.048378  0.048378"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/lib/python3/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/christinedk/venv/lib/python3.7/site-packages/ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(max_iter=500, fit_intercept=True,solver='saga')#,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6358090185676393"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[196,  94],\n",
       "       [160, 178]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5836065573770491"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thoughts:\n",
    "\n",
    "# article:\n",
    "# comparing to same pages means some features are less relevant; eg. num_editors, mean edit_size, top_contributor_frac, etc\n",
    "# recency features should be more important \n",
    "#     - calculate all features for recent revisions only as well?\n",
    "\n",
    "\n",
    "# user-article\n",
    "# empty for some negatives? sample page': 189559,'date': '2003-02-28 16:09:01'\n",
    "# revert features are incorrect, need to re-export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
