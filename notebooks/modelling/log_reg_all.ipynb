{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "HOME = '/srv/home/christinedk/wp_internship/'\n",
    "DATA_DIR = HOME + 'data/'\n",
    "sys.path.append(HOME + 'collaboration/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from math import log2\n",
    "from utils import entropy, load_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pos = load_all(HOME+'features/activity_{}.json')\n",
    "features_neg = load_all(HOME+'negative_features/activity_{}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19011"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15457"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_features_neg = pd.DataFrame([d['article'] for d in features_neg])\n",
    "article_features_neg['label'] = 0\n",
    "article_features_pos = pd.DataFrame([d['article'] for d in features_pos])\n",
    "article_features_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data = pd.concat([article_features_neg, article_features_pos])\n",
    "labels = article_data['label']\n",
    "feat = article_data.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34468"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>frac_recent_revisions</td>\n",
       "      <td>0.350963</td>\n",
       "      <td>0.350963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>concentration_ratio</td>\n",
       "      <td>0.145774</td>\n",
       "      <td>0.145774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>contribution_frac_entropy</td>\n",
       "      <td>-0.107417</td>\n",
       "      <td>0.107417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>recent_edit_size</td>\n",
       "      <td>0.103975</td>\n",
       "      <td>0.103975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>edit_size</td>\n",
       "      <td>0.102426</td>\n",
       "      <td>0.102426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>recent_response_time</td>\n",
       "      <td>0.097329</td>\n",
       "      <td>0.097329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>top_contributor_frac</td>\n",
       "      <td>0.090308</td>\n",
       "      <td>0.090308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>time_to_respond</td>\n",
       "      <td>0.079483</td>\n",
       "      <td>0.079483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>frac_anon_revisions</td>\n",
       "      <td>-0.057234</td>\n",
       "      <td>0.057234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num_revisions</td>\n",
       "      <td>-0.046866</td>\n",
       "      <td>0.046866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature     score       abs\n",
       "8       frac_recent_revisions  0.350963  0.350963\n",
       "11        concentration_ratio  0.145774  0.145774\n",
       "12  contribution_frac_entropy -0.107417  0.107417\n",
       "13           recent_edit_size  0.103975  0.103975\n",
       "0                   edit_size  0.102426  0.102426\n",
       "14       recent_response_time  0.097329  0.097329\n",
       "9        top_contributor_frac  0.090308  0.090308\n",
       "1             time_to_respond  0.079483  0.079483\n",
       "10        frac_anon_revisions -0.057234  0.057234\n",
       "6               num_revisions -0.046866  0.046866"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = {'solver':'lbfgs','max_iter':10000,'C':10000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/lib/python3/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/christinedk/venv/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7557425925016372"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2793, 1070],\n",
       "       [1760, 2994]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6790655477432525"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_features(article_users):\n",
    "    if len(article_users) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        article_users = pd.DataFrame(article_users).drop('event_user_id',axis=1)\n",
    "        means = {'mean_'+key:val for key, val in article_users.mean().items()}\n",
    "        std = {'std_'+key:val for key, val in article_users.std().items()}\n",
    "        max_ = {'max_'+key:val for key, val in article_users.max().items()}\n",
    "        ent = {'frac_page_edits_ent': entropy(article_users.frac_page_edits)}\n",
    "        features = {**means, **std, **max_, **ent}\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_article_features_pos = pd.DataFrame([aggregate_features(d['user_article']) \n",
    "                                          for d in features_pos])\n",
    "user_article_features_neg = pd.DataFrame([aggregate_features(d['user_article']) \n",
    "                                          for d in features_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_article_features_pos['label'] = 1\n",
    "user_article_features_neg['label'] = 0\n",
    "\n",
    "user_article_data = pd.concat([user_article_features_neg,user_article_features_pos])\n",
    "labels = user_article_data['label']\n",
    "feat = user_article_data.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean_frac_page_edits</td>\n",
       "      <td>0.237757</td>\n",
       "      <td>0.237757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>frac_page_edits_ent</td>\n",
       "      <td>-0.127706</td>\n",
       "      <td>0.127706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>max_frac_page_edits</td>\n",
       "      <td>0.100884</td>\n",
       "      <td>0.100884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean_edit_size</td>\n",
       "      <td>0.090631</td>\n",
       "      <td>0.090631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>std_frac_page_edits</td>\n",
       "      <td>0.089781</td>\n",
       "      <td>0.089781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean_time_to_respond</td>\n",
       "      <td>0.078438</td>\n",
       "      <td>0.078438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mean_time_responded_to</td>\n",
       "      <td>0.072992</td>\n",
       "      <td>0.072992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>std_time_to_respond</td>\n",
       "      <td>0.059014</td>\n",
       "      <td>0.059014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>std_num_edits</td>\n",
       "      <td>-0.052719</td>\n",
       "      <td>0.052719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>max_num_edits</td>\n",
       "      <td>-0.050877</td>\n",
       "      <td>0.050877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature     score       abs\n",
       "5     mean_frac_page_edits  0.237757  0.237757\n",
       "24     frac_page_edits_ent -0.127706  0.127706\n",
       "21     max_frac_page_edits  0.100884  0.100884\n",
       "0           mean_edit_size  0.090631  0.090631\n",
       "13     std_frac_page_edits  0.089781  0.089781\n",
       "2     mean_time_to_respond  0.078438  0.078438\n",
       "3   mean_time_responded_to  0.072992  0.072992\n",
       "10     std_time_to_respond  0.059014  0.059014\n",
       "12           std_num_edits -0.052719  0.052719\n",
       "20           max_num_edits -0.050877  0.050877"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6536386359081394"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2314, 1493],\n",
       "       [1922, 2888]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6284408660646285"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# talk vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_pos = load_all(HOME+'features/talk_{}.json')\n",
    "talk_neg = load_all(HOME+'negative_features/talk_{}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_vol_neg = pd.DataFrame([d['talk_volume'] for d in talk_neg])\n",
    "talk_vol_neg['label'] = 0\n",
    "talk_vol_pos = pd.DataFrame([d['talk_volume'] for d in talk_pos])\n",
    "talk_vol_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_vol = pd.concat([talk_vol_neg,talk_vol_pos])\n",
    "labels = talk_vol['label']\n",
    "feat = talk_vol.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean_response_time</td>\n",
       "      <td>0.068302</td>\n",
       "      <td>0.068302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frac_recent_revisions</td>\n",
       "      <td>0.035473</td>\n",
       "      <td>0.035473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num_editors</td>\n",
       "      <td>-0.026659</td>\n",
       "      <td>0.026659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>page_talk_ratio</td>\n",
       "      <td>-0.024916</td>\n",
       "      <td>0.024916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_revisions</td>\n",
       "      <td>-0.020181</td>\n",
       "      <td>0.020181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mean_edit_size</td>\n",
       "      <td>-0.015382</td>\n",
       "      <td>0.015382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>top_contributor_frac</td>\n",
       "      <td>0.013786</td>\n",
       "      <td>0.013786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature     score       abs\n",
       "5     mean_response_time  0.068302  0.068302\n",
       "1  frac_recent_revisions  0.035473  0.035473\n",
       "2            num_editors -0.026659  0.026659\n",
       "6        page_talk_ratio -0.024916  0.024916\n",
       "0          num_revisions -0.020181  0.020181\n",
       "4         mean_edit_size -0.015382  0.015382\n",
       "3   top_contributor_frac  0.013786  0.013786"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/lib/python3/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/christinedk/venv/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5676982862110361"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 854, 3003],\n",
       "       [ 723, 4037]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6842372881355934"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# talk lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_language(talk_feat):\n",
    "    if len(talk_feat) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        all_utts = pd.DataFrame(list(np.concatenate(list(talk_feat.values()))))\n",
    "        means = {'mean_'+key:val for key, val in all_utts.mean().items()}\n",
    "        std = {'std_'+key:val for key, val in all_utts.std().items()}\n",
    "        max_ = {'max_'+key:val for key, val in all_utts.max().items()}\n",
    "        features = {**means, **std, **max_}\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_lang_neg = pd.DataFrame([aggregate_language(d['talk_language']) for d in talk_neg])\n",
    "talk_lang_neg['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15457"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(talk_lang_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_lang_pos = pd.DataFrame([aggregate_language(d['talk_language']) for d in talk_pos])\n",
    "talk_lang_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19011"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(talk_lang_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_lang = pd.concat([talk_lang_neg,talk_lang_pos])\n",
    "labels = talk_lang['label']\n",
    "feat = talk_lang.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>max_politeness_markers_==Please==</td>\n",
       "      <td>-0.029585</td>\n",
       "      <td>0.029585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>max_politeness_markers_==Please_start==</td>\n",
       "      <td>-0.028034</td>\n",
       "      <td>0.028034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>max_politeness_markers_==1st_person_start==</td>\n",
       "      <td>-0.026753</td>\n",
       "      <td>0.026753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>max_politeness_markers_==Gratitude==</td>\n",
       "      <td>-0.026207</td>\n",
       "      <td>0.026207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>max_politeness_markers_==Indirect_(greeting)==</td>\n",
       "      <td>-0.025383</td>\n",
       "      <td>0.025383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>max_politeness_markers_==2nd_person==</td>\n",
       "      <td>-0.024626</td>\n",
       "      <td>0.024626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>max_politeness_markers_==1st_person==</td>\n",
       "      <td>-0.024332</td>\n",
       "      <td>0.024332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>max_reply_depth</td>\n",
       "      <td>-0.023883</td>\n",
       "      <td>0.023883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>max_politeness_markers_==HASHEDGE==</td>\n",
       "      <td>-0.023032</td>\n",
       "      <td>0.023032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>max_politeness_markers_==Hedges==</td>\n",
       "      <td>-0.022984</td>\n",
       "      <td>0.022984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           feature     score       abs\n",
       "44               max_politeness_markers_==Please== -0.029585  0.029585\n",
       "45         max_politeness_markers_==Please_start== -0.028034  0.028034\n",
       "55     max_politeness_markers_==1st_person_start== -0.026753  0.026753\n",
       "51            max_politeness_markers_==Gratitude== -0.026207  0.026207\n",
       "58  max_politeness_markers_==Indirect_(greeting)== -0.025383  0.025383\n",
       "56           max_politeness_markers_==2nd_person== -0.024626  0.024626\n",
       "54           max_politeness_markers_==1st_person== -0.024332  0.024332\n",
       "65                                 max_reply_depth -0.023883  0.023883\n",
       "46             max_politeness_markers_==HASHEDGE== -0.023032  0.023032\n",
       "48               max_politeness_markers_==Hedges== -0.022984  0.022984"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5096086515920547"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  82, 3815],\n",
       "       [  96, 4624]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.702788965726879"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# editors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def aggregate_editor(editor_feat):\n",
    "    if len(editor_feat) == 0:\n",
    "        return {}\n",
    "    else:\n",
    "        all_utts = pd.DataFrame(editor_feat).drop('event_user_id',axis=1)\n",
    "        means = {'mean_'+key:val for key, val in all_utts.mean().items()}\n",
    "        std = {'std_'+key:val for key, val in all_utts.std().items()}\n",
    "        max_ = {'max_'+key:val for key, val in all_utts.max().items()}\n",
    "        features = {**means, **std, **max_}\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(HOME+'features/editors{}_v2.json'.format(template),'rb') as f:\n",
    "    editors_pos = json.load(f)\n",
    "    \n",
    "with open(HOME+'negative_features/editors{}_v2.json'.format(template),'rb') as f:\n",
    "    editors_neg = json.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "editor_neg = pd.DataFrame([aggregate_editor(d['editor']) for d in editors_neg])\n",
    "editor_neg['label'] = 0\n",
    "editor_pos = pd.DataFrame([aggregate_editor(d['editor']) for d in editors_pos])\n",
    "editor_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "len(editor_neg)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "len(editor_pos)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "editor_data = pd.concat([editor_neg,editor_pos])\n",
    "labels = editor_data['label']\n",
    "feat = editor_data.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# editor-editor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def aggregate(df):\n",
    "    means = {'mean_'+key:val for key, val in df.mean().items()}\n",
    "    std = {'std_'+key:val for key, val in df.std().items()}\n",
    "    max_ = {'max_'+key:val for key, val in df.max().items()}\n",
    "    features = {**means, **std, **max_}\n",
    "    return features\n",
    "\n",
    "def aggregate_collab(editor_feat):\n",
    "    if len(editor_feat['undirected']) == 0:\n",
    "        features = {}\n",
    "        \n",
    "    else:\n",
    "        directed = pd.DataFrame(editor_feat['directed']).drop(['event_user_id','event_user_id_r'],axis=1)\n",
    "        undirected = pd.DataFrame(editor_feat['undirected']).drop('pair',axis=1)\n",
    "\n",
    "        dir_features = aggregate(directed)\n",
    "        undir_features = aggregate(undirected)\n",
    "\n",
    "        features = {**dir_features,**undir_features}\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "collab_neg = pd.DataFrame([aggregate_collab(d['collaboration']) for d in editors_neg])\n",
    "collab_neg['label'] = 0\n",
    "collab_pos = pd.DataFrame([aggregate_collab(d['collaboration']) for d in editors_pos])\n",
    "collab_pos['label'] = 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "collab_data = pd.concat([editor_neg,editor_pos])\n",
    "labels = collab_data['label']\n",
    "feat = collab_data.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)\n",
    "#C=0.1,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = article_data['label']\n",
    "\n",
    "feat = pd.concat([ds.reset_index(drop=True).drop('label',axis=1) \n",
    "                  for ds in [article_data,talk_vol,talk_lang,user_article_data]],axis=1) #editor_data,collab_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34468"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>frac_recent_revisions</td>\n",
       "      <td>0.066059</td>\n",
       "      <td>0.066059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>recent_response_time</td>\n",
       "      <td>0.060187</td>\n",
       "      <td>0.060187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>time_to_respond</td>\n",
       "      <td>0.056839</td>\n",
       "      <td>0.056839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>mean_time_to_respond</td>\n",
       "      <td>0.055441</td>\n",
       "      <td>0.055441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>article_age_years</td>\n",
       "      <td>0.053727</td>\n",
       "      <td>0.053727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mean_response_time</td>\n",
       "      <td>0.050521</td>\n",
       "      <td>0.050521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>mean_time_responded_to</td>\n",
       "      <td>0.050519</td>\n",
       "      <td>0.050519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>std_time_to_respond</td>\n",
       "      <td>0.041386</td>\n",
       "      <td>0.041386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>max_time_to_respond</td>\n",
       "      <td>0.041110</td>\n",
       "      <td>0.041110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>frac_recent_revisions</td>\n",
       "      <td>-0.040411</td>\n",
       "      <td>0.040411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature     score       abs\n",
       "8     frac_recent_revisions  0.066059  0.066059\n",
       "14     recent_response_time  0.060187  0.060187\n",
       "1           time_to_respond  0.056839  0.056839\n",
       "90     mean_time_to_respond  0.055441  0.055441\n",
       "2         article_age_years  0.053727  0.053727\n",
       "20       mean_response_time  0.050521  0.050521\n",
       "91   mean_time_responded_to  0.050519  0.050519\n",
       "98      std_time_to_respond  0.041386  0.041386\n",
       "106     max_time_to_respond  0.041110  0.041110\n",
       "16    frac_recent_revisions -0.040411  0.040411"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = feat.corrwith(labels).reset_index().rename(columns={'index':'feature',0:'score'})\n",
    "correlations['abs'] = correlations.score.abs()\n",
    "correlations.sort_values(by='abs', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/lib/python3/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/christinedk/venv/lib/python3.7/site-packages/ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(**hypers)#,class_weight={0:1,1:5}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat.fillna(0),labels)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7529580078880209"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=X_train,y=y_train)\n",
    "predictions=model.predict_proba(X_test)\n",
    "y_pred = np.argmax(predictions,axis=1)\n",
    "roc_auc_score(y_score=predictions[:,1],y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2761, 1099],\n",
       "       [1763, 2994]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred,y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6766101694915254"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thoughts:\n",
    "\n",
    "# article:\n",
    "# comparing to same pages means some features are less relevant; eg. num_editors, mean edit_size, top_contributor_frac, etc\n",
    "# recency features should be more important \n",
    "#     - calculate all features for recent revisions only as well?\n",
    "\n",
    "\n",
    "# user-article\n",
    "# empty for some negatives? sample page': 189559,'date': '2003-02-28 16:09:01'\n",
    "# revert features are incorrect, need to re-export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
