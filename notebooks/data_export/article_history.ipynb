{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "HOME='/srv/home/christinedk/wp_internship/'\n",
    "sys.path.append(HOME + 'collaboration/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time  import time\n",
    "from pyspark.sql.functions import udf, col, explode, regexp_replace\n",
    "from math import log2\n",
    "\n",
    "from data_export import getTemplatesRegexRelaibility, getTemplatesRegex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: `page_history': File exists\r\n"
     ]
    }
   ],
   "source": [
    "TEMPLATES = ['weasel','peacock','autobiography','advert','fanpov']\n",
    "outputHDFS = 'page_history'\n",
    "!hadoop fs -mkdir $outputHDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "blp = pd.read_csv('/srv/home/christinedk/wp_internship/data/namespaces.csv')\n",
    "blp_articles = blp.query('page_namespace == 0').drop_duplicates(subset=['page_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "blp_ids = blp_articles.page_id.tolist()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "blp_articles_df = spark.createDataFrame(blp_articles)\n",
    "blp_articles_df.createOrReplaceTempView('blp_articles_tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           partition|\n",
      "+--------------------+\n",
      "|snapshot=2021-01/...|\n",
      "|snapshot=2021-01/...|\n",
      "|snapshot=2021-01/...|\n",
      "|snapshot=2021-01/...|\n",
      "|snapshot=2021-01/...|\n",
      "|snapshot=2021-01/...|\n",
      "|snapshot=2021-01/...|\n",
      "|snapshot=2021-01/...|\n",
      "|snapshot=2021-01/...|\n",
      "|snapshot=2021-01/...|\n",
      "|snapshot=2021-01/...|\n",
      "|snapshot=2021-01/...|\n",
      "|snapshot=2021-01/...|\n",
      "|snapshot=2021-01/...|\n",
      "|snapshot=2021-01/...|\n",
      "|snapshot=2021-01/...|\n",
      "|snapshot=2021-01/...|\n",
      "|snapshot=2021-01/...|\n",
      "|snapshot=2021-01/...|\n",
      "|snapshot=2021-01/...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('show partitions wmf.mediawiki_wikitext_history').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all revisions with templates from WikiText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[page_id: bigint, page_title: string, revision_id: bigint, revision_text: string, user_id: bigint]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot =\"2021-01\"\n",
    "wikidb = \"enwiki\"\n",
    "wikitext_history = spark.sql('''SELECT page_id,page_title,revision_id,revision_text,user_id\n",
    "    FROM wmf.mediawiki_wikitext_history \n",
    "    WHERE snapshot =\"{snapshot}\" and wiki_db =\"{wikidb}\"\n",
    "    '''.format(wikidb=wikidb,snapshot=snapshot))\n",
    "\n",
    "wikitext_history.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blp_history = wikitext_history.filter(col('page_id').isin(blp_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "revisions_with_template = blp_history.withColumn(\"templates\",getTemplatesRegexRelaibility(col('revision_text')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "revisions_with_template = revisions_with_template.select(revisions_with_template.page_id,revisions_with_template.page_title,\n",
    "                                             revisions_with_template.user_id,revisions_with_template.revision_id,\n",
    "                                             explode(revisions_with_template.templates))\\\n",
    "                                             .withColumn('page_title', regexp_replace('page_title', ' ', '_'))\\\n",
    "#.filter(revisions_with_template['user_id']!=7328338)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Persist outputs\n",
    "revisions_with_template.write.parquet('page_history/templates.parquet',mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get full edit history of pages and editors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "revisions_with_template = spark.read.parquet('page_history/templates.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595759"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revisions_with_template.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select subset of mediawiki history containing all page titles with revisions\n",
    "\n",
    "pages_templates_subset = revisions_with_template.select('page_title').distinct()\n",
    "pages_templates_subset.createOrReplaceTempView('pages_templates_subset')\n",
    "\n",
    "mediawiki_history_subset =  spark.sql('''\n",
    "        SELECT w.event_timestamp, w.page_title,w.page_id,w.page_namespace, \n",
    "        w.revision_id, w.revision_is_identity_reverted,  w.revision_is_identity_revert,\n",
    "        w.revision_minor_edit, w.revision_text_bytes, \n",
    "        w.revision_first_identity_reverting_revision_id, w.revision_seconds_to_identity_revert,\n",
    "        w.event_user_id,w.event_user_registration_timestamp, \n",
    "        w.event_user_is_anonymous,w.event_user_revision_count,\n",
    "\n",
    "        w.event_comment\n",
    "        FROM wmf.mediawiki_history w\n",
    "        WHERE w.snapshot =\"2020-09\" and w.wiki_db =\"enwiki\" AND  \n",
    "        w.event_entity = 'revision' AND w.page_title IN (\n",
    "                    SELECT page_title FROM pages_templates_subset)                   \n",
    "        ''')\n",
    "mediawiki_history_subset.cache()\n",
    "mediawiki_history_subset.createOrReplaceTempView('mediawiki_history_subset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weasel\n",
      "read table, done 0.32538866996765137\n",
      "save table, done -0.0001862049102783203\n",
      "21/03/23 13:25:03 INFO compress.CodecPool: Got brand-new decompressor [.snappy]\n",
      "----- 8.036737442016602\n",
      "peacock\n",
      "read table, done 0.08455944061279297\n",
      "save table, done -0.00018930435180664062\n",
      "21/03/23 13:26:00 INFO compress.CodecPool: Got brand-new decompressor [.snappy]\n",
      "----- 8.262783527374268\n",
      "autobiography\n",
      "read table, done 0.08574676513671875\n",
      "save table, done -0.00019311904907226562\n",
      "21/03/23 13:26:38 INFO compress.CodecPool: Got brand-new decompressor [.snappy]\n",
      "----- 6.469390869140625\n",
      "advert\n",
      "read table, done 0.08558392524719238\n",
      "save table, done -0.0001220703125\n",
      "21/03/23 13:27:14 INFO compress.CodecPool: Got brand-new decompressor [.snappy]\n",
      "----- 7.935754060745239\n",
      "fanpov\n",
      "read table, done 0.08685660362243652\n",
      "save table, done -0.00018525123596191406\n",
      "21/03/23 13:27:49 INFO compress.CodecPool: Got brand-new decompressor [.snappy]\n",
      "----- 6.46190619468689\n"
     ]
    }
   ],
   "source": [
    "## Get full histories of these pages\n",
    "\n",
    "for template in TEMPLATES:\n",
    "    try:\n",
    "        outputHDFS = 'page_history'\n",
    "        t1 = time()\n",
    "        print(template)\n",
    "        df = revisions_with_template.where(revisions_with_template['col']==template) # \n",
    "        df.cache()\n",
    "        t2 = time()\n",
    "        print('read table, done',t2-t1)\n",
    "        t1 = time()\n",
    "        page_ids = df.select('page_title').distinct()\n",
    "        page_ids.createOrReplaceTempView('tmp_page_ids')\n",
    "        revision_ids = df.select('revision_id').distinct()\n",
    "        revision_ids.createOrReplaceTempView('tmp_revision_ids')\n",
    "        reverts = spark.sql('''\n",
    "        SELECT w.event_timestamp, w.page_title,w.page_id, \n",
    "        w.page_namespace,w.revision_id, \n",
    "        w.revision_is_identity_reverted, w.revision_is_identity_revert,\n",
    "        w.revision_minor_edit, w.revision_text_bytes, \n",
    "        w.revision_first_identity_reverting_revision_id,\n",
    "        w.event_user_id,w.event_user_registration_timestamp, \n",
    "        w.event_user_is_anonymous,w.event_user_revision_count,\n",
    "        CASE WHEN r.revision_id IS NOT NULL  THEN 1 ELSE 0 END has_template,\n",
    "        w.event_comment\n",
    "        FROM mediawiki_history_subset w \n",
    "        LEFT OUTER JOIN tmp_revision_ids r \n",
    "        ON (w.revision_id = r.revision_id)\n",
    "        WHERE  w.page_title IN (SELECT page_title FROM tmp_page_ids) \n",
    "        ORDER BY page_title, w.revision_id\n",
    "        ''') \n",
    "        reverts.write.format('json').save(outputHDFS+'/'+template,mode='overwrite')\n",
    "        print('save table, done',t2-t1)\n",
    "        t1 = time()   \n",
    "        templateout = template.replace(' ','_')\n",
    "        !hadoop fs -text \"$outputHDFS/$template/*\" > $outputHDFS-$template-meta-info.json\n",
    "        t2 = time()\n",
    "        print('-----',t2-t1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print('error',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv page_history* ../data/page_history/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article_history.ipynb           extract_talk_features.ipynb\r\n",
      "categories.ipynb                preprocess_editor_history.ipynb\r\n",
      "\u001b[0m\u001b[01;34mdeprecated\u001b[0m/                     tag_addition_analysis.ipynb\r\n",
      "EDA_revisions.ipynb             tags_meta.ipynb\r\n",
      "editor_history.ipynb            talk_page_history.ipynb\r\n",
      "extract_article_features.ipynb  user_histories_analysis.ipynb\r\n",
      "extract_editor_features.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark - YARN (large)",
   "language": "python",
   "name": "spark_yarn_pyspark_large"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
