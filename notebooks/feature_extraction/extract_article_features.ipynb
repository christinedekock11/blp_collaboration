{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/srv/home/christinedk/wp_internship/collaboration/')\n",
    "from utils import get_edits_pre_tag\n",
    "from features.article_history import *\n",
    "from features.politeness import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "from dateutil import parser\n",
    "import datetime\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import matplotlib.pylab as plt\n",
    "from math import log2\n",
    "from features.talk_history import ConvParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = '/srv/home/christinedk/wp_internship/'\n",
    "DATA_DIR = HOME + 'data/'\n",
    "\n",
    "def read_revisions(filename, rename=False):\n",
    "    revisions = pd.read_json(filename,lines=True)\n",
    "    if rename:\n",
    "        revisions = revisions.rename(columns = {'revision_timestamp':'event_timestamp','user_id':'event_user_id'})\n",
    "    revisions['event_timestamp'] = pd.to_datetime(revisions['event_timestamp'])\n",
    "    revisions = revisions.sort_values(by='event_timestamp', ascending=True)\n",
    "    return revisions\n",
    "\n",
    "def np_encoder(object):\n",
    "    if isinstance(object, np.generic):\n",
    "        return object.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mcollaboration\u001b[0m/  \u001b[01;34mdata\u001b[0m/  \u001b[01;34mfeatures\u001b[0m/  \u001b[01;34mnotebooks\u001b[0m/  README.md  \u001b[01;34mscripts\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls /srv/home/christinedk/wp_internship/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fanpov\n",
      "read data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 721/721 [00:13<00:00, 53.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weasel\n",
      "read data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1322/1322 [00:27<00:00, 48.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autobiography\n",
      "read data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4224/4224 [01:51<00:00, 37.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advert\n",
      "read data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7570/7570 [02:25<00:00, 52.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peacock\n",
      "read data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5174/5174 [01:50<00:00, 46.86it/s]\n"
     ]
    }
   ],
   "source": [
    "for template in ['fanpov','weasel','autobiography','advert','peacock']:\n",
    "    print(template)\n",
    "    \n",
    "    print('reading data')\n",
    "    # read and format things\n",
    "    page_revisions = read_revisions(DATA_DIR+'page_history/page_history-{}-meta-info.json'.format(template))\n",
    "    article_talk_mappings = pd.read_csv(DATA_DIR+'article_talk_mappings/{}.csv'.format(template),\n",
    "                                       usecols=['talk_page_id','article_page_id'])\n",
    "    labels = pd.read_csv(DATA_DIR+'labels/{}.csv'.format(template),parse_dates=['event_timestamp'])\n",
    "    labels = labels.join(article_talk_mappings.set_index('article_page_id')[['talk_page_id']],on='page_id')\n",
    "    \n",
    "    # prepare to extract by page\n",
    "    pages = page_revisions.groupby('page_id')\n",
    "    \n",
    "    features = []\n",
    "    for tag_date, page_id, talk_page_id in tqdm(labels.values):\n",
    "        user_article_feat = article_feat = {}\n",
    "\n",
    "        page_revisions = pages.get_group(page_id)\n",
    "        page_revisions = page_revisions[page_revisions.event_timestamp <= tag_date]\n",
    "\n",
    "        if len(page_revisions) > 0:\n",
    "            page_revisions = calculate_page_metrics(page_revisions)\n",
    "            # user-article\n",
    "            user_article_feat = get_user_article_features(page_revisions)\n",
    "            # article\n",
    "            article_feat = get_article_features(page_revisions, tag_date)\n",
    "                \n",
    "        features.append({'page':page_id,'date':str(tag_date),\n",
    "                        'user_article':user_article_feat,\n",
    "                        'article':article_feat})\n",
    "    with open(HOME +'features/activity_'+template+'.json','w') as f:\n",
    "        json.dump(features,f,default=np_encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fanpov\n",
      "read data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 721/721 [00:13<00:00, 53.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weasel\n",
      "read data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1322/1322 [00:27<00:00, 48.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autobiography\n",
      "read data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4224/4224 [01:51<00:00, 37.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advert\n",
      "read data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7570/7570 [02:25<00:00, 52.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peacock\n",
      "read data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5174/5174 [01:50<00:00, 46.86it/s]\n"
     ]
    }
   ],
   "source": [
    "for template in ['fanpov','weasel','autobiography','advert','peacock']:\n",
    "    print(template)\n",
    "    \n",
    "    print('reading data')\n",
    "    # read and format things\n",
    "    page_revisions = read_revisions(DATA_DIR+'page_history/page_history-{}-meta-info.json'.format(template))\n",
    "    talk_revisions = read_revisions(DATA_DIR+'talk_history/talk-activity-{}-meta-info.json'.format(template),\n",
    "                                    rename=True)\n",
    "    article_talk_mappings = pd.read_csv(DATA_DIR+'article_talk_mappings/{}.csv'.format(template),\n",
    "                                       usecols=['talk_page_id','article_page_id'])\n",
    "    labels = pd.read_csv(DATA_DIR+'labels/{}.csv'.format(template),parse_dates=['event_timestamp'])\n",
    "    labels = labels.join(article_talk_mappings.set_index('article_page_id')[['talk_page_id']],on='page_id')\n",
    "    \n",
    "    # prepare to extract by page\n",
    "    pages = page_revisions.groupby('page_id')\n",
    "    talk_pages = talk_revisions.groupby('page_id')\n",
    "    \n",
    "    features = []\n",
    "    for tag_date, page_id, talk_page_id in tqdm(labels.values):\n",
    "        talk_features = user_article_feat = article_feat = {}\n",
    "\n",
    "        page_revisions = pages.get_group(page_id)\n",
    "        page_revisions = page_revisions[page_revisions.event_timestamp <= tag_date]\n",
    "\n",
    "        if len(page_revisions) > 0:\n",
    "            page_revisions = calculate_page_metrics(page_revisions)\n",
    "            # user-article\n",
    "            user_article_feat = get_user_article_features(page_revisions)\n",
    "            # article\n",
    "            article_feat = get_article_features(page_revisions, tag_date)\n",
    "\n",
    "        if not np.isnan(talk_page_id):\n",
    "            tag_talk_revisions = talk_pages.get_group(talk_page_id)\n",
    "            tag_talk_revisions = tag_talk_revisions[tag_talk_revisions.event_timestamp.dt.date <= tag_date]\n",
    "\n",
    "            if len(tag_talk_revisions) > 0:\n",
    "                tag_talk_revisions = calculate_page_metrics(tag_talk_revisions)\n",
    "\n",
    "                # talk page; volume\n",
    "                talk_features = get_talk_features(tag_talk_revisions)\n",
    "                talk_features['page_talk_ratio'] = len(page_revisions)/len(tag_talk_revisions)\n",
    "                \n",
    "        features.append({'page':page_id,'date':str(tag_date),\n",
    "                        'user_article':user_article_feat,\n",
    "                        'article':article_feat,\n",
    "                        'talk':talk_features})\n",
    "    with open(HOME +'features/activity_'+template+'.json','w') as f:\n",
    "        json.dump(features,f,default=np_encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = 'fanpov'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revisions = pd.read_json('/srv/home/christinedk/wp_internship/data/page_history/page_history-{}-meta-info.json'.format(template),\n",
    "                        lines=True)\n",
    "revisions['event_timestamp'] = pd.to_datetime(revisions['event_timestamp'])\n",
    "revisions = revisions.sort_values(by='event_timestamp', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('/srv/home/christinedk/wp_internship/data/labels/{}.csv'.format(template),\n",
    "                              parse_dates=['event_timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_revisions = pd.read_json('/srv/home/christinedk/wp_internship/data/talk_history/talk-activity-{}-meta-info.json'.format(template),\n",
    "             lines=True)\n",
    "talk_revisions.rename(columns = {'revision_timestamp':'event_timestamp','user_id':'event_user_id'},inplace=True)\n",
    "talk_revisions['event_timestamp'] = pd.to_datetime(talk_revisions['event_timestamp'])\n",
    "talk_revisions = talk_revisions.sort_values(by='event_timestamp', ascending=True)\n",
    "\n",
    "article_talk_mappings = pd.read_csv('/srv/home/christinedk/wp_internship/data/article_talk_mappings/{}.csv'.format(template))[['talk_page_id','article_page_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.join(article_talk_mappings.set_index('article_page_id')[['talk_page_id']],on='page_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pages = revisions.groupby('page_id')\n",
    "talk_pages = talk_revisions.groupby('page_id')\n",
    "conv_parser = ConvParser()\n",
    "\n",
    "features = []\n",
    "\n",
    "for tag_date, page_id, talk_page_id in tqdm(labels.values):\n",
    "    talk_features = lang_features = user_article_feat = article_feat = {}\n",
    "\n",
    "    page_revisions = pages.get_group(page_id)\n",
    "    page_revisions = page_revisions[page_revisions.event_timestamp <= tag_date]\n",
    "\n",
    "    if len(page_revisions) > 0:\n",
    "        page_revisions = calculate_page_metrics(page_revisions)\n",
    "        # user-article\n",
    "        user_article_feat = get_user_article_features(page_revisions)\n",
    "        # article\n",
    "        article_feat = get_article_features(page_revisions, tag_date)\n",
    "      \n",
    "    if not np.isnan(talk_page_id):\n",
    "        tag_talk_revisions = talk_pages.get_group(talk_page_id)\n",
    "        tag_talk_revisions = tag_talk_revisions[tag_talk_revisions.event_timestamp.dt.date <= tag_date]\n",
    "\n",
    "        if len(tag_talk_revisions) > 0:\n",
    "            tag_talk_revisions = calculate_page_metrics(tag_talk_revisions)\n",
    "\n",
    "            # talk page; volume\n",
    "            talk_features = get_talk_features(tag_talk_revisions)\n",
    "            talk_features['page_talk_ratio'] = len(page_revisions)/len(tag_talk_revisions)\n",
    "\n",
    "            # talk page; language\n",
    "            talk_latest = tag_talk_revisions[['revision_text','page_id']].iloc[-1].values\n",
    "            lang_features = conv_parser.get_language_features(*talk_latest)\n",
    "    \n",
    "    features.append({'page':page_id,'date':tag_date,\n",
    "                    'user_article':user_article_feat,\n",
    "                    'article':article_feat,\n",
    "                    'talk':talk_features})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
